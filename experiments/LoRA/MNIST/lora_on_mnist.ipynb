{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a85fefe6-e3e9-44b2-9bdc-fc03d30080b6",
   "metadata": {},
   "source": [
    "# LoRA on MNIST  \n",
    "This notebook will attempt to implement Low-Rank Adaptation(LoRA) Finetuning from scratch on the MNIST dataset using pytorch lightning. I'm purposely using a simple model and data that way I can focus on LoRA implementation. \n",
    "\n",
    "Plan\n",
    "1. Build an MLP. Train this model to perform well on MNIST 0-4 (half of the data).\n",
    "3. Use standard finetuning approach to train this model to work on MNIST 5-9 (this will act as our baseline)\n",
    "4. Use LoRA finetuning to train the original model to work on MNIST 5-9\n",
    "5. Compare finetuning techniques (performance, memory etc)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37e02a5d-8dd2-4361-b7cf-9d33b025a410",
   "metadata": {},
   "source": [
    "Sources:\n",
    "1. https://arxiv.org/abs/2106.09685 - LoRA paper\n",
    "2. https://lightning.ai/pages/community/tutorial/lora-llm/ - (The first half offers useful starter pseudocode)\n",
    "3. https://colab.research.google.com/drive/1iERDk94Jp0UErsPf7vXyPKeiM4ZJUQ-a?usp=sharing#scrollTo=WuK0lPwcB7Ia - had some good ideas on metrics to compute about LoRA-ized model\n",
    "4. https://lightning.ai/docs/pytorch/stable/notebooks/lightning_examples/mnist-hello-world.html - starter code for building an MLP and training on MNIST\n",
    "5. https://discuss.pytorch.org/t/how-to-use-one-class-of-number-in-mnist/26276/21 - forum post on how to limit MNIST to only first or second half"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "423b1158-1d05-4a05-b5b2-f5a0edc9ba88",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mrigankp/.local/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "Seed set to 42\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "42"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mlightning\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mL\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mlightning\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpytorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mloggers\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m CSVLogger\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mlightning\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpytorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcallbacks\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m LearningRateFinder\n",
      "File \u001b[0;32m<frozen importlib._bootstrap>:1176\u001b[0m, in \u001b[0;36m_find_and_load\u001b[0;34m(name, import_)\u001b[0m\n",
      "File \u001b[0;32m<frozen importlib._bootstrap>:1138\u001b[0m, in \u001b[0;36m_find_and_load_unlocked\u001b[0;34m(name, import_)\u001b[0m\n",
      "File \u001b[0;32m<frozen importlib._bootstrap>:1078\u001b[0m, in \u001b[0;36m_find_spec\u001b[0;34m(name, path, target)\u001b[0m\n",
      "File \u001b[0;32m<frozen importlib._bootstrap_external>:1504\u001b[0m, in \u001b[0;36mfind_spec\u001b[0;34m(cls, fullname, path, target)\u001b[0m\n",
      "File \u001b[0;32m<frozen importlib._bootstrap_external>:1473\u001b[0m, in \u001b[0;36m_get_spec\u001b[0;34m(cls, fullname, path, target)\u001b[0m\n",
      "File \u001b[0;32m<frozen importlib._bootstrap_external>:1431\u001b[0m, in \u001b[0;36m_path_importer_cache\u001b[0;34m(cls, path)\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import lightning as L\n",
    "from lightning.pytorch.loggers import CSVLogger\n",
    "from lightning.pytorch.callbacks import LearningRateFinder\n",
    "from lightning.pytorch.callbacks.early_stopping import EarlyStopping\n",
    "\n",
    "from pytorch_lightning import Callback\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.nn import functional as F\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "from torch.utils.data.sampler import SubsetRandomSampler\n",
    "\n",
    "import torchvision\n",
    "from torchvision.datasets import MNIST\n",
    "from torchvision import transforms\n",
    "\n",
    "from torchmetrics import Accuracy\n",
    "\n",
    "import pandas as pd\n",
    "import seaborn as sn\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# set precision to what lightning suggests for this gpu\n",
    "torch.set_float32_matmul_precision('high')\n",
    "# make results reproducible\n",
    "L.seed_everything(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9fd83ca-88db-4682-85e1-904d4f5df759",
   "metadata": {},
   "outputs": [],
   "source": [
    "# reserved for constants\n",
    "PATH_DATASETS = 'mnist'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7665fd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create another dataset called \"quantized_mnist\" where feature values are rounded to 0 or 255\n",
    "\n",
    "class QuantizedMNIST(MNIST):\n",
    "    def __init__(self, *args, **kwargs):\n",
    "        super().__init__(*args, **kwargs)\n",
    "        self.transform = transforms.Compose(\n",
    "            [\n",
    "                transforms.ToTensor(),\n",
    "                transforms.Lambda(lambda x: torch.round(x)),\n",
    "            ]\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a973882e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create another dataset called \"inversecolor_mnist\" where all pixel values are inverted\n",
    "# class InverseColorMNIST(MNIST):\n",
    "#     def __init__(self, *args, **kwargs):\n",
    "#         super().__init__(*args, **kwargs)\n",
    "#         self.transform = transforms.Compose(\n",
    "#             [\n",
    "#                 transforms.ToTensor(),\n",
    "#                 transforms.Lambda(lambda x: 1 - x),\n",
    "#             ]\n",
    "#         )\n",
    "        \n",
    "# Create another dataset called \"inverted_mnist\" where all images are rotated by 180 degrees\n",
    "class InvertedMNIST(MNIST):\n",
    "    def __init__(self, *args, **kwargs):\n",
    "        super().__init__(*args, **kwargs)\n",
    "        self.transform = transforms.Compose(\n",
    "            [\n",
    "                transforms.ToTensor(),\n",
    "                transforms.Lambda(lambda x: x.rot90(2, [1, 2])),\n",
    "            ]\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d712261-bb19-459d-8272-b33e529bc613",
   "metadata": {},
   "source": [
    "Train an MLP on full MNIST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27414d79-396d-460d-8700-aee7169c20bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LitMNIST(L.LightningModule):\n",
    "    def __init__(self, data_dir=PATH_DATASETS, hidden_size=64, lr=2e-4, ver='n'):\n",
    "        \"\"\"\n",
    "        'ver' is 'n' for normal mnist, 'q' for quantized mnist\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        \n",
    "        self.version = ver\n",
    "\n",
    "        # Set our init args as class attributes\n",
    "        self.data_dir = data_dir\n",
    "        self.hidden_size = hidden_size\n",
    "        self.lr = lr\n",
    "\n",
    "        # Hardcode some dataset specific attributes\n",
    "        self.class_names = [0,1,2,3,4,5,6,7,8,9]\n",
    "        self.min_class = min(self.class_names)\n",
    "        self.num_classes = len(self.class_names) \n",
    "        self.dims = (1, 28, 28) # the shape of an example (C x W x H)\n",
    "        channels, width, height = self.dims\n",
    "\n",
    "        self.transform = transforms.Compose(\n",
    "            [\n",
    "                transforms.ToTensor(),\n",
    "                transforms.Normalize((0.1307,), (0.3081,)),\n",
    "            ]\n",
    "        )\n",
    "\n",
    "        self.batch_size = 1024\n",
    "\n",
    "        # Define layers for model\n",
    "        self.l1 = nn.Linear(channels * width * height, hidden_size)\n",
    "        self.l2 = nn.Linear(hidden_size, hidden_size)\n",
    "        self.l3 = nn.Linear(hidden_size, self.num_classes)\n",
    "\n",
    "        self.dropout = nn.Dropout(0.1)\n",
    "        self.relu = nn.ReLU()\n",
    "\n",
    "        \n",
    "        # Define metrics\n",
    "        self.val_accuracy = Accuracy(task=\"multiclass\", num_classes=self.num_classes)\n",
    "        self.test_accuracy = Accuracy(task=\"multiclass\", num_classes=self.num_classes)\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        # preprocessing\n",
    "        x = torch.flatten(x,1)\n",
    "\n",
    "        # layer 1 (input size, hidden size)\n",
    "        x = self.l1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.dropout(x)\n",
    "\n",
    "        # layer 2 (hidden size, hidden size)\n",
    "        x = self.l2(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.dropout(x)\n",
    "\n",
    "        #layer 3 (hidden size, self.num_classes)\n",
    "        x = self.l3(x)\n",
    "                    \n",
    "        # notice that we return the log probabilities here as that is what nll loss expects in the training step\n",
    "        return F.log_softmax(x, dim=1)\n",
    "\n",
    "    def common_step(self, batch, batch_idx):\n",
    "        # define steps all of {train, val, test} will take in one place\n",
    "        x, y = batch\n",
    "        # rescale y to be 0 indexed if necessary (like when we start using mnist 5-9)\n",
    "        if self.min_class != 0:\n",
    "            y = y - self.min_class\n",
    "        \n",
    "        logits = self(x)\n",
    "        loss = F.nll_loss(logits, y)\n",
    "        return x,y, logits, loss\n",
    "        \n",
    "        \n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        _, _, _, loss = self.common_step(batch, batch_idx)\n",
    "        self.log(\"train_loss\", loss, batch_size=self.batch_size)\n",
    "        return loss\n",
    "\n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        \n",
    "        x, y, logits, loss = self.common_step(batch, batch_idx)\n",
    "        preds = torch.argmax(logits, dim=1)\n",
    "        self.val_accuracy.update(preds, y)\n",
    "\n",
    "        self.log(\"val_loss\", loss, prog_bar=True)\n",
    "        self.log(\"val_acc\", self.val_accuracy, prog_bar=True)\n",
    "\n",
    "    def test_step(self, batch, batch_idx):\n",
    "        x, y, logits, loss = self.common_step(batch, batch_idx)\n",
    "        preds = torch.argmax(logits, dim=1)\n",
    "        self.test_accuracy.update(preds, y)\n",
    "\n",
    "        self.log(\"test_loss\", loss, prog_bar=True)\n",
    "        self.log(\"test_acc\", self.test_accuracy, prog_bar=True)\n",
    "    \n",
    "    def configure_optimizers(self):\n",
    "        # we'll use adamw to match the paper\n",
    "        optimizer = torch.optim.AdamW(self.parameters(), lr=self.lr)\n",
    "        return optimizer\n",
    "\n",
    "    # the rest of the class is helper functions/hooks for configuring data/dataloader building\n",
    "    @staticmethod\n",
    "    def get_indices(dataset,class_names):\n",
    "        if isinstance(dataset, torch.utils.data.dataset.Subset):\n",
    "            targets = torch.tensor([dataset.dataset.targets[i] for i in dataset.indices])\n",
    "        else:\n",
    "            targets = dataset.targets\n",
    "\n",
    "            \n",
    "        indices =  []\n",
    "        for i in range(len(targets)):\n",
    "            if targets[i] in class_names:\n",
    "                indices.append(i)\n",
    "        return indices\n",
    "        \n",
    "    def create_dataloader(self,dataset):\n",
    "        idx = self.get_indices(dataset, self.class_names)\n",
    "        loader = DataLoader(dataset,batch_size=self.batch_size, sampler = SubsetRandomSampler(idx), num_workers=16) # Note - this necessarily shuffles the data due to the sampler we are using\n",
    "        return loader\n",
    "\n",
    "    def prepare_data(self):\n",
    "        # download data\n",
    "        if self.version == 'n':\n",
    "            MNIST(self.data_dir, train=True, download=True)\n",
    "            MNIST(self.data_dir, train=False, download=True)\n",
    "        if self.version == 'q':\n",
    "            print(\"Checkpoint-(0)\")\n",
    "            QuantizedMNIST(self.data_dir, train=True, download=True)\n",
    "            QuantizedMNIST(self.data_dir, train=False, download=True)\n",
    "        if self.version == 'i':\n",
    "            print(\"Checkpoint-(10)\")\n",
    "            InvertedMNIST(self.data_dir, train=True, download=True)\n",
    "            InvertedMNIST(self.data_dir, train=False, download=True)\n",
    "\n",
    "    def setup(self, stage=None):\n",
    "        # Assign train/val datasets for use in dataloaders\n",
    "        if self.version == 'n':\n",
    "            if stage == \"fit\" or stage is None:\n",
    "                mnist_full = MNIST(self.data_dir, train=True, transform=self.transform)\n",
    "                self.mnist_train, self.mnist_val = random_split(mnist_full, [55000, 5000])\n",
    "        if self.version == 'q':\n",
    "            print(\"Checkpoint-(1)\")\n",
    "            if stage == \"fit\" or stage is None:\n",
    "                mnist_full = QuantizedMNIST(self.data_dir, train=True, transform=self.transform)\n",
    "                self.mnist_train, self.mnist_val = random_split(mnist_full, [55000, 5000])\n",
    "        if self.version == 'i':\n",
    "            print(\"Checkpoint-(11)\")\n",
    "            if stage == \"fit\" or stage is None:\n",
    "                mnist_full = InvertedMNIST(self.data_dir, train=True, transform=self.transform)\n",
    "                self.mnist_train, self.mnist_val = random_split(mnist_full, [55000, 5000])\n",
    "\n",
    "            \n",
    "\n",
    "        # Assign test dataset for use in dataloader(s)\n",
    "        if self.version == 'n':\n",
    "            if stage == \"test\" or stage is None:\n",
    "                self.mnist_test = MNIST(self.data_dir, train=False, transform=self.transform)\n",
    "        if self.version == 'q':\n",
    "            if stage == \"test\" or stage is None:\n",
    "                self.mnist_test = QuantizedMNIST(self.data_dir, train=False, transform=self.transform)   \n",
    "        if self.version == 'i':\n",
    "            if stage == \"test\" or stage is None:\n",
    "                self.mnist_test = InvertedMNIST(self.data_dir, train=False, transform=self.transform)            \n",
    "\n",
    "    def train_dataloader(self):\n",
    "        return self.create_dataloader(self.mnist_train)\n",
    "\n",
    "    def val_dataloader(self):\n",
    "        return self.create_dataloader(self.mnist_val)\n",
    "\n",
    "    def test_dataloader(self):\n",
    "        return self.create_dataloader(self.mnist_test)\n",
    "    \n",
    "    def predict(self, x):\n",
    "        logits = self(x)\n",
    "        return torch.argmax(logits, dim=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcea2f7d-cb12-44df-96b0-e832632e905f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name          | Type               | Params\n",
      "-----------------------------------------------------\n",
      "0 | l1            | Linear             | 50.2 K\n",
      "1 | l2            | Linear             | 4.2 K \n",
      "2 | l3            | Linear             | 650   \n",
      "3 | dropout       | Dropout            | 0     \n",
      "4 | relu          | ReLU               | 0     \n",
      "5 | val_accuracy  | MulticlassAccuracy | 0     \n",
      "6 | test_accuracy | MulticlassAccuracy | 0     \n",
      "-----------------------------------------------------\n",
      "55.1 K    Trainable params\n",
      "0         Non-trainable params\n",
      "55.1 K    Total params\n",
      "0.220     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9: 100%|██████████| 54/54 [00:01<00:00, 29.93it/s, v_num=6, val_loss=0.248, val_acc=0.928]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=10` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9: 100%|██████████| 54/54 [00:01<00:00, 29.86it/s, v_num=6, val_loss=0.248, val_acc=0.928]\n"
     ]
    }
   ],
   "source": [
    "model = LitMNIST()\n",
    "trainer = L.Trainer(\n",
    "    accelerator=\"auto\",\n",
    "    devices=1,\n",
    "    max_epochs=10,\n",
    "    logger=CSVLogger(save_dir=\"logs/\"),\n",
    ")\n",
    "trainer.fit(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa45d80a-ea43-41a5-a8f4-a60ac95717bb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>train_loss</th>\n",
       "      <th>val_acc</th>\n",
       "      <th>val_loss</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>epoch</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.533384</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.7104</td>\n",
       "      <td>1.366489</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.808736</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.8364</td>\n",
       "      <td>0.680481</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.596579</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       train_loss  val_acc  val_loss\n",
       "epoch                               \n",
       "0        1.533384      NaN       NaN\n",
       "0             NaN   0.7104  1.366489\n",
       "1        0.808736      NaN       NaN\n",
       "1             NaN   0.8364  0.680481\n",
       "2        0.596579      NaN       NaN"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mrigankp/.local/lib/python3.11/site-packages/seaborn/axisgrid.py:123: UserWarning: The figure layout has changed to tight\n",
      "  self._figure.tight_layout(*args, **kwargs)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<seaborn.axisgrid.FacetGrid at 0x7a8914976190>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 616.125x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "metrics = pd.read_csv(f\"{trainer.logger.log_dir}/metrics.csv\")\n",
    "del metrics[\"step\"]\n",
    "metrics.set_index(\"epoch\", inplace=True)\n",
    "display(metrics.dropna(axis=1, how=\"all\").head())\n",
    "sn.relplot(data=metrics, kind=\"line\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6dc1512-5f6d-46a3-8129-1cea54a92aa3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Restoring states from the checkpoint path at logs/lightning_logs/version_6/checkpoints/epoch=9-step=540.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "Loaded model weights from the checkpoint at logs/lightning_logs/version_6/checkpoints/epoch=9-step=540.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing DataLoader 0: 100%|██████████| 10/10 [00:00<00:00, 202.64it/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\">        Test metric        </span>┃<span style=\"font-weight: bold\">       DataLoader 0        </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         test_acc          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.9311000108718872     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         test_loss         </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.2292446345090866     </span>│\n",
       "└───────────────────────────┴───────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1m       Test metric       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      DataLoader 0       \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│\u001b[36m \u001b[0m\u001b[36m        test_acc         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.9311000108718872    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m        test_loss        \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.2292446345090866    \u001b[0m\u001b[35m \u001b[0m│\n",
       "└───────────────────────────┴───────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[{'test_loss': 0.2292446345090866, 'test_acc': 0.9311000108718872}]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# as expected our model performs well\n",
    "trainer.test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46379ebe-33f9-468a-a833-4dfefc489f8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save model weights so we can finetune from them later\n",
    "trainer.save_checkpoint(\"model.ckpt\")\n",
    "torch.save(model.state_dict(), 'model.pt')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad0a1f3b-6fe5-4839-b8d3-92f177c86ecb",
   "metadata": {},
   "source": [
    "# Finetune on Quantized MNIST and Inverted MNIST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "742a8381",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create the dataset\n",
    "quantized_mnist = QuantizedMNIST(PATH_DATASETS, train=True, download=True)\n",
    "\n",
    "# create a dataloader\n",
    "quantized_mnist_loader = DataLoader(quantized_mnist, batch_size=1024, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4217ecc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8455833333333334\n"
     ]
    }
   ],
   "source": [
    "# test the accuracy of the model on entire quantized dataset\n",
    "acc = 0\n",
    "for x, y in quantized_mnist_loader:\n",
    "    preds = model.predict(x)\n",
    "    acc += torch.sum(preds == y).item()\n",
    "    \n",
    "acc /= len(quantized_mnist)\n",
    "\n",
    "print(acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73902b9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create the dataset\n",
    "inverted_mnist = InvertedMNIST(PATH_DATASETS, train=True, download=True)\n",
    "\n",
    "# create a dataloader\n",
    "inverted_mnist_loader = DataLoader(inverted_mnist, batch_size=1024, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b759d1f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.1484\n"
     ]
    }
   ],
   "source": [
    "# test the accuracy of the model on entire quantized dataset\n",
    "acc = 0\n",
    "for x, y in inverted_mnist_loader:\n",
    "    preds = model.predict(x)\n",
    "    acc += torch.sum(preds == y).item()\n",
    "    \n",
    "acc /= len(quantized_mnist)\n",
    "\n",
    "print(acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "500cdb8b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name          | Type               | Params\n",
      "-----------------------------------------------------\n",
      "0 | l1            | Linear             | 50.2 K\n",
      "1 | l2            | Linear             | 4.2 K \n",
      "2 | l3            | Linear             | 650   \n",
      "3 | dropout       | Dropout            | 0     \n",
      "4 | relu          | ReLU               | 0     \n",
      "5 | val_accuracy  | MulticlassAccuracy | 0     \n",
      "6 | test_accuracy | MulticlassAccuracy | 0     \n",
      "-----------------------------------------------------\n",
      "55.1 K    Trainable params\n",
      "0         Non-trainable params\n",
      "55.1 K    Total params\n",
      "0.220     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checkpoint-(0)\n",
      "Checkpoint-(1)\n",
      "Epoch 9: 100%|██████████| 54/54 [00:01<00:00, 33.99it/s, v_num=8, val_loss=0.236, val_acc=0.934]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=10` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9: 100%|██████████| 54/54 [00:01<00:00, 33.89it/s, v_num=8, val_loss=0.236, val_acc=0.934]\n"
     ]
    }
   ],
   "source": [
    "# now finetune e2e on the new data\n",
    "model_quantized = LitMNIST.load_from_checkpoint(checkpoint_path=\"model.ckpt\")\n",
    "model_quantized.version = 'q'\n",
    "\n",
    "trainer = L.Trainer(\n",
    "    accelerator=\"auto\",\n",
    "    devices=1,\n",
    "    max_epochs=10,\n",
    "    logger=CSVLogger(save_dir=\"logs/\"),\n",
    ")\n",
    "trainer.fit(model_quantized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "289d2534",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checkpoint-(10)\n",
      "Checkpoint-(11)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name          | Type               | Params\n",
      "-----------------------------------------------------\n",
      "0 | l1            | Linear             | 50.2 K\n",
      "1 | l2            | Linear             | 4.2 K \n",
      "2 | l3            | Linear             | 650   \n",
      "3 | dropout       | Dropout            | 0     \n",
      "4 | relu          | ReLU               | 0     \n",
      "5 | val_accuracy  | MulticlassAccuracy | 0     \n",
      "6 | test_accuracy | MulticlassAccuracy | 0     \n",
      "-----------------------------------------------------\n",
      "55.1 K    Trainable params\n",
      "0         Non-trainable params\n",
      "55.1 K    Total params\n",
      "0.220     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9: 100%|██████████| 54/54 [00:01<00:00, 34.26it/s, v_num=9, val_loss=0.280, val_acc=0.922]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=10` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9: 100%|██████████| 54/54 [00:01<00:00, 34.16it/s, v_num=9, val_loss=0.280, val_acc=0.922]\n"
     ]
    }
   ],
   "source": [
    "# now finetune e2e on the new data\n",
    "model_inverted = LitMNIST.load_from_checkpoint(checkpoint_path=\"model.ckpt\")\n",
    "model_inverted.version = 'i'\n",
    "\n",
    "trainer = L.Trainer(\n",
    "    accelerator=\"auto\",\n",
    "    devices=1,\n",
    "    max_epochs=10,\n",
    "    logger=CSVLogger(save_dir=\"logs/\"),\n",
    ")\n",
    "trainer.fit(model_inverted)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b37c4c1e-8141-4416-a0a1-1f8e596abd17",
   "metadata": {},
   "source": [
    "# Finetune on quantized MNIST using LoRA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27563e84-9d50-480c-9202-91d7b5ec518c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LitMNISTLoRA(L.LightningModule):\n",
    "    def __init__(self, data_dir=PATH_DATASETS, hidden_size=64, lr=2e-4, lora_rank = 8):\n",
    "        super().__init__()\n",
    "\n",
    "        # Set our init args as class attributes\n",
    "        self.data_dir = data_dir\n",
    "        self.hidden_size = hidden_size\n",
    "        self.lr = lr\n",
    "\n",
    "        # Hardcode some dataset specific attributes\n",
    "        self.class_names = [0,1,2,3,4,5,6,7,8,9]\n",
    "        self.min_class = min(self.class_names)\n",
    "        self.num_classes = len(self.class_names) \n",
    "        self.dims = (1, 28, 28) # the shape of an example (C x W x H)\n",
    "        channels, width, height = self.dims\n",
    "\n",
    "        self.transform = transforms.Compose(\n",
    "            [\n",
    "                transforms.ToTensor(),\n",
    "                transforms.Normalize((0.1307,), (0.3081,)),\n",
    "            ]\n",
    "        )\n",
    "\n",
    "        self.batch_size = 1024 # 64\n",
    "        \n",
    "        # Define layers for model\n",
    "        self.l1 = nn.Linear(channels * width * height, hidden_size)\n",
    "        self.l2 = nn.Linear(hidden_size, hidden_size)\n",
    "        self.l3 = nn.Linear(hidden_size, self.num_classes)\n",
    "\n",
    "        self.dropout = nn.Dropout(0.1)\n",
    "        self.relu = nn.ReLU()\n",
    "\n",
    "        # Define lora hyperparameters\n",
    "        self.lora_rank = lora_rank # The rank 'r' for the low-rank adaptation\n",
    "        self.lora_alpha = 1 # lora scaling factor\n",
    "        \n",
    "        # layer 1 lora layers\n",
    "        self.l1_lora_A = nn.Parameter(torch.empty(channels * width * height, self.lora_rank))\n",
    "        self.l1_lora_B = nn.Parameter(torch.empty(self.lora_rank, hidden_size))\n",
    "\n",
    "        # layer 2 lora layers\n",
    "        self.l2_lora_A =  nn.Parameter(torch.empty(hidden_size, self.lora_rank))\n",
    "        self.l2_lora_B = nn.Parameter(torch.empty(self.lora_rank, hidden_size))\n",
    "\n",
    "        # layer 3 lora layers\n",
    "        self.l3_lora_A = nn.Parameter(torch.empty(hidden_size, self.lora_rank))\n",
    "        self.l3_lora_B = nn.Parameter(torch.empty(self.lora_rank, self.num_classes))\n",
    "        \n",
    "        # Define initialization for lora layers (this ensures that the model behavior is identital to to the original model prior to finetuning)\n",
    "        for n,p in self.named_parameters():\n",
    "            if 'lora' in n:\n",
    "                if n[-1]=='A':\n",
    "                    nn.init.kaiming_uniform_(p, a=math.sqrt(5))\n",
    "                elif n[-1]=='B':\n",
    "                    nn.init.zeros_(p)\n",
    "\n",
    "        # freeze non lora weights\n",
    "        for n,p in self.named_parameters():\n",
    "            if 'lora' not in n:\n",
    "                p.requires_grad = False\n",
    "        \n",
    "        # Define metrics\n",
    "        self.val_accuracy = Accuracy(task=\"multiclass\", num_classes=self.num_classes)\n",
    "        self.test_accuracy = Accuracy(task=\"multiclass\", num_classes=self.num_classes)\n",
    "\n",
    "\n",
    "    def lora_linear(self, x, layer, lora_A, lora_B):\n",
    "        # does the work of combining outputs from normal layer and lora layer for x\n",
    "        # notice that h is the sum of two separate operations on x\n",
    "        h = layer(x)\n",
    "        h += x@(lora_A @ lora_B)*self.lora_alpha\n",
    "        return h\n",
    "        \n",
    "    def forward(self, x):\n",
    "        # preprocessing\n",
    "        x = torch.flatten(x,1)\n",
    "        \n",
    "        # layer 1 (input size, hidden size)\n",
    "        x = self.lora_linear(x, self.l1, self.l1_lora_A, self.l1_lora_B)\n",
    "        x = self.relu(x)\n",
    "        x = self.dropout(x)\n",
    "\n",
    "        # layer 2 (hidden size, hidden size)\n",
    "        x = self.lora_linear(x, self.l2, self.l2_lora_A, self.l2_lora_B)\n",
    "        x = self.relu(x)\n",
    "        x = self.dropout(x)\n",
    "\n",
    "        #layer 3 (hidden size, self.num_classes)\n",
    "        x = self.lora_linear(x, self.l3, self.l3_lora_A, self.l3_lora_B)\n",
    "                    \n",
    "        # notice that we return the log probabilities here as that is what nll loss expects in the training step\n",
    "        return F.log_softmax(x, dim=1)\n",
    "\n",
    "    def common_step(self, batch, batch_idx):\n",
    "        # define steps all of {train, val, test} will take in one place\n",
    "        x, y = batch\n",
    "        # rescale y to be 0 indexed if necessary (like when we start using mnist 5-9)\n",
    "        if self.min_class != 0:\n",
    "            y = y - self.min_class\n",
    "        \n",
    "        logits = self(x)\n",
    "        loss = F.nll_loss(logits, y)\n",
    "        return x,y, logits, loss\n",
    "        \n",
    "        \n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        _, _, _, loss = self.common_step(batch, batch_idx)\n",
    "        self.log(\"train_loss\", loss, batch_size=self.batch_size)\n",
    "        return loss\n",
    "\n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        x, y, logits, loss = self.common_step(batch, batch_idx)\n",
    "        preds = torch.argmax(logits, dim=1)\n",
    "        self.val_accuracy.update(preds, y)\n",
    "\n",
    "        self.log(\"val_loss\", loss, prog_bar=False)\n",
    "        self.log(\"val_acc\", self.val_accuracy, prog_bar=True)\n",
    "\n",
    "    def test_step(self, batch, batch_idx):\n",
    "        x, y, logits, loss = self.common_step(batch, batch_idx)\n",
    "        preds = torch.argmax(logits, dim=1)\n",
    "        self.test_accuracy.update(preds, y)\n",
    "\n",
    "        self.log(\"test_loss\", loss, prog_bar=True)\n",
    "        self.log(\"test_acc\", self.test_accuracy, prog_bar=True)\n",
    "    \n",
    "    def configure_optimizers(self):\n",
    "        # we'll use adamw to match the paper\n",
    "        optimizer = torch.optim.AdamW(self.parameters(), lr=self.lr)\n",
    "        scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, 'min', patience=10)\n",
    "\n",
    "        return {\n",
    "        \"optimizer\": optimizer,\n",
    "        \"lr_scheduler\": {\n",
    "            \"scheduler\": scheduler,\n",
    "            \"monitor\": \"val_loss\",\n",
    "            \"frequency\": 1\n",
    "        },\n",
    "        }\n",
    "\n",
    "      \n",
    "    # the rest of the class is helper functions/hooks for configuring data/dataloader building\n",
    "    @staticmethod\n",
    "    def get_indices(dataset,class_names):\n",
    "        if isinstance(dataset, torch.utils.data.dataset.Subset):\n",
    "            targets = torch.tensor([dataset.dataset.targets[i] for i in dataset.indices])\n",
    "        else:\n",
    "            targets = dataset.targets\n",
    "\n",
    "            \n",
    "        indices =  []\n",
    "        for i in range(len(targets)):\n",
    "            if targets[i] in class_names:\n",
    "                indices.append(i)\n",
    "        return indices\n",
    "        \n",
    "    def create_dataloader(self,dataset):\n",
    "        idx = self.get_indices(dataset, self.class_names)\n",
    "        loader = DataLoader(dataset,batch_size=self.batch_size, sampler = SubsetRandomSampler(idx), num_workers=16) # Note - this necessarily shuffles the data due to the sampler we are using\n",
    "        return loader\n",
    "\n",
    "    def prepare_data(self):\n",
    "        # download data\n",
    "        QuantizedMNIST(self.data_dir, train=True, download=True)\n",
    "        QuantizedMNIST(self.data_dir, train=False, download=True)\n",
    "\n",
    "    def setup(self, stage=None):\n",
    "        # Assign train/val datasets for use in dataloaders\n",
    "        if stage == \"fit\" or stage is None:\n",
    "            mnist_full = QuantizedMNIST(self.data_dir, train=True, transform=self.transform)\n",
    "            self.mnist_train, self.mnist_val = random_split(mnist_full, [55000, 5000])\n",
    "\n",
    "        # Assign test dataset for use in dataloader(s)\n",
    "        if stage == \"test\" or stage is None:\n",
    "            self.mnist_test = QuantizedMNIST(self.data_dir, train=False, transform=self.transform)\n",
    "\n",
    "    def train_dataloader(self):\n",
    "        return self.create_dataloader(self.mnist_train)\n",
    "\n",
    "    def val_dataloader(self):\n",
    "        return self.create_dataloader(self.mnist_val)\n",
    "\n",
    "    def test_dataloader(self):\n",
    "        return self.create_dataloader(self.mnist_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44986317-f1ec-4b53-b68d-47b0db656ac1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# try lora finetuning with different lora ranks\n",
    "def lora_experiment(rank):\n",
    "    state_dict = torch.load(\"model.pt\")\n",
    "    model = LitMNISTLoRA(lora_rank=rank,)\n",
    "    model.load_state_dict(state_dict, strict=False)\n",
    "    \n",
    "    from lightning.pytorch.callbacks import LearningRateMonitor\n",
    "    lr_monitor = LearningRateMonitor(logging_interval='step')\n",
    "    \n",
    "    trainer = L.Trainer(\n",
    "        accelerator=\"auto\",\n",
    "        devices=1,\n",
    "        max_epochs=10,\n",
    "        callbacks=[lr_monitor, EarlyStopping(monitor=\"val_loss\", mode=\"min\", patience=10)],\n",
    "\n",
    "        enable_progress_bar=False\n",
    "    )\n",
    "    \n",
    "    trainer.fit(model)\n",
    "    return trainer.test()[0]['test_acc']\n",
    "\n",
    "# try lora full training with different lora ranks\n",
    "def lora_experiment_fulltrain(rank):\n",
    "    # state_dict = torch.load(\"model.pt\")\n",
    "    model = LitMNISTLoRA(lora_rank=rank,)\n",
    "    # model.load_state_dict(state_dict, strict=False)\n",
    "    \n",
    "    from lightning.pytorch.callbacks import LearningRateMonitor\n",
    "    lr_monitor = LearningRateMonitor(logging_interval='step')\n",
    "    \n",
    "    trainer = L.Trainer(\n",
    "        accelerator=\"auto\",\n",
    "        devices=1,\n",
    "        max_epochs=10,\n",
    "        callbacks=[lr_monitor, EarlyStopping(monitor=\"val_loss\", mode=\"min\", patience=10)],\n",
    "\n",
    "        enable_progress_bar=False\n",
    "    )\n",
    "    \n",
    "    trainer.fit(model)\n",
    "    return trainer.test()[0]['test_acc']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6dcee69-a9c7-4bb9-80a9-2bb5d8747cc9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/mrigankp/.local/lib/python3.11/site-packages/lightning/pytorch/trainer/connectors/logger_connector/logger_connector.py:75: Starting from v1.9.0, `tensorboardX` has been removed as a dependency of the `lightning.pytorch` package, due to potential conflicts with other packages in the ML ecosystem. For this reason, `logger=True` will use `CSVLogger` as the default logger, unless the `tensorboard` or `tensorboardX` packages are found. Please `pip install lightning[extra]` or one of them to enable TensorBoard support by default\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name          | Type               | Params\n",
      "-----------------------------------------------------\n",
      "0 | l1            | Linear             | 50.2 K\n",
      "1 | l2            | Linear             | 4.2 K \n",
      "2 | l3            | Linear             | 650   \n",
      "3 | dropout       | Dropout            | 0     \n",
      "4 | relu          | ReLU               | 0     \n",
      "5 | val_accuracy  | MulticlassAccuracy | 0     \n",
      "6 | test_accuracy | MulticlassAccuracy | 0     \n",
      "  | other params  | n/a                | 1.1 K \n",
      "-----------------------------------------------------\n",
      "1.1 K     Trainable params\n",
      "55.1 K    Non-trainable params\n",
      "56.1 K    Total params\n",
      "0.224     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=10` reached.\n",
      "Restoring states from the checkpoint path at /home/mrigankp/OneDrive/Course/Sem 4/UMC 203/Term Paper/experiments/LoRA/lightning_logs/version_22/checkpoints/epoch=9-step=540.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "Loaded model weights from the checkpoint at /home/mrigankp/OneDrive/Course/Sem 4/UMC 203/Term Paper/experiments/LoRA/lightning_logs/version_22/checkpoints/epoch=9-step=540.ckpt\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\">        Test metric        </span>┃<span style=\"font-weight: bold\">       DataLoader 0        </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         test_acc          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.9063000082969666     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         test_loss         </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.5468206405639648     </span>│\n",
       "└───────────────────────────┴───────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1m       Test metric       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      DataLoader 0       \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│\u001b[36m \u001b[0m\u001b[36m        test_acc         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.9063000082969666    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m        test_loss        \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.5468206405639648    \u001b[0m\u001b[35m \u001b[0m│\n",
       "└───────────────────────────┴───────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rank 1 Accuracy: 0.9063000082969666, Time: 34.9063 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name          | Type               | Params\n",
      "-----------------------------------------------------\n",
      "0 | l1            | Linear             | 50.2 K\n",
      "1 | l2            | Linear             | 4.2 K \n",
      "2 | l3            | Linear             | 650   \n",
      "3 | dropout       | Dropout            | 0     \n",
      "4 | relu          | ReLU               | 0     \n",
      "5 | val_accuracy  | MulticlassAccuracy | 0     \n",
      "6 | test_accuracy | MulticlassAccuracy | 0     \n",
      "  | other params  | n/a                | 2.1 K \n",
      "-----------------------------------------------------\n",
      "2.1 K     Trainable params\n",
      "55.1 K    Non-trainable params\n",
      "57.1 K    Total params\n",
      "0.229     Total estimated model params size (MB)\n",
      "`Trainer.fit` stopped: `max_epochs=10` reached.\n",
      "Restoring states from the checkpoint path at /home/mrigankp/OneDrive/Course/Sem 4/UMC 203/Term Paper/experiments/LoRA/lightning_logs/version_23/checkpoints/epoch=9-step=540.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "Loaded model weights from the checkpoint at /home/mrigankp/OneDrive/Course/Sem 4/UMC 203/Term Paper/experiments/LoRA/lightning_logs/version_23/checkpoints/epoch=9-step=540.ckpt\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\">        Test metric        </span>┃<span style=\"font-weight: bold\">       DataLoader 0        </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         test_acc          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">     0.909500002861023     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         test_loss         </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.48807552456855774    </span>│\n",
       "└───────────────────────────┴───────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1m       Test metric       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      DataLoader 0       \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│\u001b[36m \u001b[0m\u001b[36m        test_acc         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    0.909500002861023    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m        test_loss        \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.48807552456855774   \u001b[0m\u001b[35m \u001b[0m│\n",
       "└───────────────────────────┴───────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rank 2 Accuracy: 0.909500002861023, Time: 34.6526 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name          | Type               | Params\n",
      "-----------------------------------------------------\n",
      "0 | l1            | Linear             | 50.2 K\n",
      "1 | l2            | Linear             | 4.2 K \n",
      "2 | l3            | Linear             | 650   \n",
      "3 | dropout       | Dropout            | 0     \n",
      "4 | relu          | ReLU               | 0     \n",
      "5 | val_accuracy  | MulticlassAccuracy | 0     \n",
      "6 | test_accuracy | MulticlassAccuracy | 0     \n",
      "  | other params  | n/a                | 4.2 K \n",
      "-----------------------------------------------------\n",
      "4.2 K     Trainable params\n",
      "55.1 K    Non-trainable params\n",
      "59.2 K    Total params\n",
      "0.237     Total estimated model params size (MB)\n",
      "`Trainer.fit` stopped: `max_epochs=10` reached.\n",
      "Restoring states from the checkpoint path at /home/mrigankp/OneDrive/Course/Sem 4/UMC 203/Term Paper/experiments/LoRA/lightning_logs/version_24/checkpoints/epoch=9-step=540.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "Loaded model weights from the checkpoint at /home/mrigankp/OneDrive/Course/Sem 4/UMC 203/Term Paper/experiments/LoRA/lightning_logs/version_24/checkpoints/epoch=9-step=540.ckpt\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\">        Test metric        </span>┃<span style=\"font-weight: bold\">       DataLoader 0        </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         test_acc          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.9121999740600586     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         test_loss         </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.41099658608436584    </span>│\n",
       "└───────────────────────────┴───────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1m       Test metric       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      DataLoader 0       \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│\u001b[36m \u001b[0m\u001b[36m        test_acc         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.9121999740600586    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m        test_loss        \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.41099658608436584   \u001b[0m\u001b[35m \u001b[0m│\n",
       "└───────────────────────────┴───────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rank 4 Accuracy: 0.9121999740600586, Time: 25.2445 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name          | Type               | Params\n",
      "-----------------------------------------------------\n",
      "0 | l1            | Linear             | 50.2 K\n",
      "1 | l2            | Linear             | 4.2 K \n",
      "2 | l3            | Linear             | 650   \n",
      "3 | dropout       | Dropout            | 0     \n",
      "4 | relu          | ReLU               | 0     \n",
      "5 | val_accuracy  | MulticlassAccuracy | 0     \n",
      "6 | test_accuracy | MulticlassAccuracy | 0     \n",
      "  | other params  | n/a                | 8.4 K \n",
      "-----------------------------------------------------\n",
      "8.4 K     Trainable params\n",
      "55.1 K    Non-trainable params\n",
      "63.5 K    Total params\n",
      "0.254     Total estimated model params size (MB)\n",
      "`Trainer.fit` stopped: `max_epochs=10` reached.\n",
      "Restoring states from the checkpoint path at /home/mrigankp/OneDrive/Course/Sem 4/UMC 203/Term Paper/experiments/LoRA/lightning_logs/version_25/checkpoints/epoch=9-step=540.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "Loaded model weights from the checkpoint at /home/mrigankp/OneDrive/Course/Sem 4/UMC 203/Term Paper/experiments/LoRA/lightning_logs/version_25/checkpoints/epoch=9-step=540.ckpt\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\">        Test metric        </span>┃<span style=\"font-weight: bold\">       DataLoader 0        </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         test_acc          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.9133999943733215     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         test_loss         </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.3427736759185791     </span>│\n",
       "└───────────────────────────┴───────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1m       Test metric       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      DataLoader 0       \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│\u001b[36m \u001b[0m\u001b[36m        test_acc         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.9133999943733215    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m        test_loss        \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.3427736759185791    \u001b[0m\u001b[35m \u001b[0m│\n",
       "└───────────────────────────┴───────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rank 8 Accuracy: 0.9133999943733215, Time: 33.7363 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name          | Type               | Params\n",
      "-----------------------------------------------------\n",
      "0 | l1            | Linear             | 50.2 K\n",
      "1 | l2            | Linear             | 4.2 K \n",
      "2 | l3            | Linear             | 650   \n",
      "3 | dropout       | Dropout            | 0     \n",
      "4 | relu          | ReLU               | 0     \n",
      "5 | val_accuracy  | MulticlassAccuracy | 0     \n",
      "6 | test_accuracy | MulticlassAccuracy | 0     \n",
      "  | other params  | n/a                | 16.8 K\n",
      "-----------------------------------------------------\n",
      "16.8 K    Trainable params\n",
      "55.1 K    Non-trainable params\n",
      "71.9 K    Total params\n",
      "0.287     Total estimated model params size (MB)\n",
      "`Trainer.fit` stopped: `max_epochs=10` reached.\n",
      "Restoring states from the checkpoint path at /home/mrigankp/OneDrive/Course/Sem 4/UMC 203/Term Paper/experiments/LoRA/lightning_logs/version_26/checkpoints/epoch=9-step=540.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "Loaded model weights from the checkpoint at /home/mrigankp/OneDrive/Course/Sem 4/UMC 203/Term Paper/experiments/LoRA/lightning_logs/version_26/checkpoints/epoch=9-step=540.ckpt\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\">        Test metric        </span>┃<span style=\"font-weight: bold\">       DataLoader 0        </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         test_acc          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.9199000000953674     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         test_loss         </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.2971551716327667     </span>│\n",
       "└───────────────────────────┴───────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1m       Test metric       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      DataLoader 0       \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│\u001b[36m \u001b[0m\u001b[36m        test_acc         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.9199000000953674    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m        test_loss        \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.2971551716327667    \u001b[0m\u001b[35m \u001b[0m│\n",
       "└───────────────────────────┴───────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rank 16 Accuracy: 0.9199000000953674, Time: 34.5702 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name          | Type               | Params\n",
      "-----------------------------------------------------\n",
      "0 | l1            | Linear             | 50.2 K\n",
      "1 | l2            | Linear             | 4.2 K \n",
      "2 | l3            | Linear             | 650   \n",
      "3 | dropout       | Dropout            | 0     \n",
      "4 | relu          | ReLU               | 0     \n",
      "5 | val_accuracy  | MulticlassAccuracy | 0     \n",
      "6 | test_accuracy | MulticlassAccuracy | 0     \n",
      "  | other params  | n/a                | 33.6 K\n",
      "-----------------------------------------------------\n",
      "33.6 K    Trainable params\n",
      "55.1 K    Non-trainable params\n",
      "88.7 K    Total params\n",
      "0.355     Total estimated model params size (MB)\n",
      "`Trainer.fit` stopped: `max_epochs=10` reached.\n",
      "Restoring states from the checkpoint path at /home/mrigankp/OneDrive/Course/Sem 4/UMC 203/Term Paper/experiments/LoRA/lightning_logs/version_27/checkpoints/epoch=9-step=540.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "Loaded model weights from the checkpoint at /home/mrigankp/OneDrive/Course/Sem 4/UMC 203/Term Paper/experiments/LoRA/lightning_logs/version_27/checkpoints/epoch=9-step=540.ckpt\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\">        Test metric        </span>┃<span style=\"font-weight: bold\">       DataLoader 0        </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         test_acc          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.9253000020980835     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         test_loss         </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.26633894443511963    </span>│\n",
       "└───────────────────────────┴───────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1m       Test metric       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      DataLoader 0       \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│\u001b[36m \u001b[0m\u001b[36m        test_acc         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.9253000020980835    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m        test_loss        \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.26633894443511963   \u001b[0m\u001b[35m \u001b[0m│\n",
       "└───────────────────────────┴───────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name          | Type               | Params\n",
      "-----------------------------------------------------\n",
      "0 | l1            | Linear             | 50.2 K\n",
      "1 | l2            | Linear             | 4.2 K \n",
      "2 | l3            | Linear             | 650   \n",
      "3 | dropout       | Dropout            | 0     \n",
      "4 | relu          | ReLU               | 0     \n",
      "5 | val_accuracy  | MulticlassAccuracy | 0     \n",
      "6 | test_accuracy | MulticlassAccuracy | 0     \n",
      "  | other params  | n/a                | 67.2 K\n",
      "-----------------------------------------------------\n",
      "67.2 K    Trainable params\n",
      "55.1 K    Non-trainable params\n",
      "122 K     Total params\n",
      "0.489     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rank 32 Accuracy: 0.9253000020980835, Time: 24.8980 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=10` reached.\n",
      "Restoring states from the checkpoint path at /home/mrigankp/OneDrive/Course/Sem 4/UMC 203/Term Paper/experiments/LoRA/lightning_logs/version_28/checkpoints/epoch=9-step=540.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "Loaded model weights from the checkpoint at /home/mrigankp/OneDrive/Course/Sem 4/UMC 203/Term Paper/experiments/LoRA/lightning_logs/version_28/checkpoints/epoch=9-step=540.ckpt\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\">        Test metric        </span>┃<span style=\"font-weight: bold\">       DataLoader 0        </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         test_acc          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">     0.930400013923645     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         test_loss         </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.23627407848834991    </span>│\n",
       "└───────────────────────────┴───────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1m       Test metric       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      DataLoader 0       \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│\u001b[36m \u001b[0m\u001b[36m        test_acc         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    0.930400013923645    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m        test_loss        \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.23627407848834991   \u001b[0m\u001b[35m \u001b[0m│\n",
       "└───────────────────────────┴───────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rank 64 Accuracy: 0.930400013923645, Time: 32.3039 seconds\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "results = {}\n",
    "for rank in [1, 2, 4, 8, 16, 32, 64]:\n",
    "    start_time = time.time()\n",
    "    result = lora_experiment(rank)\n",
    "    end_time = time.time()\n",
    "    elapsed_time = end_time - start_time\n",
    "\n",
    "    results[rank] = (result, elapsed_time)  # Store both accuracy and time\n",
    "    print(f\"Rank {rank} Accuracy: {result}, Time: {elapsed_time:.4f} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4a7b68e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{1: (0.9063000082969666, 34.9062557220459),\n",
       " 2: (0.909500002861023, 34.65264916419983),\n",
       " 4: (0.9121999740600586, 25.24445414543152),\n",
       " 8: (0.9133999943733215, 33.73633813858032),\n",
       " 16: (0.9199000000953674, 34.570229053497314),\n",
       " 32: (0.9253000020980835, 24.897957801818848),\n",
       " 64: (0.930400013923645, 32.30386519432068)}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9280b829",
   "metadata": {},
   "outputs": [],
   "source": [
    "# full training\n",
    "\n",
    "results = {}\n",
    "for rank in [1, 2, 4, 8, 16, 32, 64]:\n",
    "    start_time = time.time()\n",
    "    result = lora_experiment_fulltrain(rank)\n",
    "    end_time = time.time()\n",
    "    elapsed_time = end_time - start_time\n",
    "\n",
    "    results[rank] = (result, elapsed_time)  # Store both accuracy and time\n",
    "    print(f\"Rank {rank} Accuracy: {result}, Time: {elapsed_time:.4f} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fe23d87",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LitMNISTLoRA_Inverted(L.LightningModule):\n",
    "    def __init__(self, data_dir=PATH_DATASETS, hidden_size=64, lr=2e-4, lora_rank = 8):\n",
    "        super().__init__()\n",
    "\n",
    "        # Set our init args as class attributes\n",
    "        self.data_dir = data_dir\n",
    "        self.hidden_size = hidden_size\n",
    "        self.lr = lr\n",
    "\n",
    "        # Hardcode some dataset specific attributes\n",
    "        self.class_names = [0,1,2,3,4,5,6,7,8,9]\n",
    "        self.min_class = min(self.class_names)\n",
    "        self.num_classes = len(self.class_names) \n",
    "        self.dims = (1, 28, 28) # the shape of an example (C x W x H)\n",
    "        channels, width, height = self.dims\n",
    "\n",
    "        self.transform = transforms.Compose(\n",
    "            [\n",
    "                transforms.ToTensor(),\n",
    "                transforms.Normalize((0.1307,), (0.3081,)),\n",
    "            ]\n",
    "        )\n",
    "\n",
    "        self.batch_size = 1024 # 64\n",
    "        \n",
    "        # Define layers for model\n",
    "        self.l1 = nn.Linear(channels * width * height, hidden_size)\n",
    "        self.l2 = nn.Linear(hidden_size, hidden_size)\n",
    "        self.l3 = nn.Linear(hidden_size, self.num_classes)\n",
    "\n",
    "        self.dropout = nn.Dropout(0.1)\n",
    "        self.relu = nn.ReLU()\n",
    "\n",
    "        # Define lora hyperparameters\n",
    "        self.lora_rank = lora_rank # The rank 'r' for the low-rank adaptation\n",
    "        self.lora_alpha = 1 # lora scaling factor\n",
    "        \n",
    "        # layer 1 lora layers\n",
    "        self.l1_lora_A = nn.Parameter(torch.empty(channels * width * height, self.lora_rank))\n",
    "        self.l1_lora_B = nn.Parameter(torch.empty(self.lora_rank, hidden_size))\n",
    "\n",
    "        # layer 2 lora layers\n",
    "        self.l2_lora_A =  nn.Parameter(torch.empty(hidden_size, self.lora_rank))\n",
    "        self.l2_lora_B = nn.Parameter(torch.empty(self.lora_rank, hidden_size))\n",
    "\n",
    "        # layer 3 lora layers\n",
    "        self.l3_lora_A = nn.Parameter(torch.empty(hidden_size, self.lora_rank))\n",
    "        self.l3_lora_B = nn.Parameter(torch.empty(self.lora_rank, self.num_classes))\n",
    "        \n",
    "        # Define initialization for lora layers (this ensures that the model behavior is identital to to the original model prior to finetuning)\n",
    "        for n,p in self.named_parameters():\n",
    "            if 'lora' in n:\n",
    "                if n[-1]=='A':\n",
    "                    nn.init.kaiming_uniform_(p, a=math.sqrt(5))\n",
    "                elif n[-1]=='B':\n",
    "                    nn.init.zeros_(p)\n",
    "\n",
    "        # freeze non lora weights\n",
    "        for n,p in self.named_parameters():\n",
    "            if 'lora' not in n:\n",
    "                p.requires_grad = False\n",
    "        \n",
    "        # Define metrics\n",
    "        self.val_accuracy = Accuracy(task=\"multiclass\", num_classes=self.num_classes)\n",
    "        self.test_accuracy = Accuracy(task=\"multiclass\", num_classes=self.num_classes)\n",
    "\n",
    "\n",
    "    def lora_linear(self, x, layer, lora_A, lora_B):\n",
    "        # does the work of combining outputs from normal layer and lora layer for x\n",
    "        # notice that h is the sum of two separate operations on x\n",
    "        h = layer(x)\n",
    "        h += x@(lora_A @ lora_B)*self.lora_alpha\n",
    "        return h\n",
    "        \n",
    "    def forward(self, x):\n",
    "        # preprocessing\n",
    "        x = torch.flatten(x,1)\n",
    "        \n",
    "        # layer 1 (input size, hidden size)\n",
    "        x = self.lora_linear(x, self.l1, self.l1_lora_A, self.l1_lora_B)\n",
    "        x = self.relu(x)\n",
    "        x = self.dropout(x)\n",
    "\n",
    "        # layer 2 (hidden size, hidden size)\n",
    "        x = self.lora_linear(x, self.l2, self.l2_lora_A, self.l2_lora_B)\n",
    "        x = self.relu(x)\n",
    "        x = self.dropout(x)\n",
    "\n",
    "        #layer 3 (hidden size, self.num_classes)\n",
    "        x = self.lora_linear(x, self.l3, self.l3_lora_A, self.l3_lora_B)\n",
    "                    \n",
    "        # notice that we return the log probabilities here as that is what nll loss expects in the training step\n",
    "        return F.log_softmax(x, dim=1)\n",
    "\n",
    "    def common_step(self, batch, batch_idx):\n",
    "        # define steps all of {train, val, test} will take in one place\n",
    "        x, y = batch\n",
    "        # rescale y to be 0 indexed if necessary (like when we start using mnist 5-9)\n",
    "        if self.min_class != 0:\n",
    "            y = y - self.min_class\n",
    "        \n",
    "        logits = self(x)\n",
    "        loss = F.nll_loss(logits, y)\n",
    "        return x,y, logits, loss\n",
    "        \n",
    "        \n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        _, _, _, loss = self.common_step(batch, batch_idx)\n",
    "        self.log(\"train_loss\", loss, batch_size=self.batch_size)\n",
    "        return loss\n",
    "\n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        x, y, logits, loss = self.common_step(batch, batch_idx)\n",
    "        preds = torch.argmax(logits, dim=1)\n",
    "        self.val_accuracy.update(preds, y)\n",
    "\n",
    "        self.log(\"val_loss\", loss, prog_bar=False)\n",
    "        self.log(\"val_acc\", self.val_accuracy, prog_bar=True)\n",
    "\n",
    "    def test_step(self, batch, batch_idx):\n",
    "        x, y, logits, loss = self.common_step(batch, batch_idx)\n",
    "        preds = torch.argmax(logits, dim=1)\n",
    "        self.test_accuracy.update(preds, y)\n",
    "\n",
    "        self.log(\"test_loss\", loss, prog_bar=True)\n",
    "        self.log(\"test_acc\", self.test_accuracy, prog_bar=True)\n",
    "    \n",
    "    def configure_optimizers(self):\n",
    "        # we'll use adamw to match the paper\n",
    "        optimizer = torch.optim.AdamW(self.parameters(), lr=self.lr)\n",
    "        scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, 'min', patience=10)\n",
    "\n",
    "        return {\n",
    "        \"optimizer\": optimizer,\n",
    "        \"lr_scheduler\": {\n",
    "            \"scheduler\": scheduler,\n",
    "            \"monitor\": \"val_loss\",\n",
    "            \"frequency\": 1\n",
    "        },\n",
    "        }\n",
    "\n",
    "      \n",
    "    # the rest of the class is helper functions/hooks for configuring data/dataloader building\n",
    "    @staticmethod\n",
    "    def get_indices(dataset,class_names):\n",
    "        if isinstance(dataset, torch.utils.data.dataset.Subset):\n",
    "            targets = torch.tensor([dataset.dataset.targets[i] for i in dataset.indices])\n",
    "        else:\n",
    "            targets = dataset.targets\n",
    "\n",
    "            \n",
    "        indices =  []\n",
    "        for i in range(len(targets)):\n",
    "            if targets[i] in class_names:\n",
    "                indices.append(i)\n",
    "        return indices\n",
    "        \n",
    "    def create_dataloader(self,dataset):\n",
    "        idx = self.get_indices(dataset, self.class_names)\n",
    "        loader = DataLoader(dataset,batch_size=self.batch_size, sampler = SubsetRandomSampler(idx), num_workers=16) # Note - this necessarily shuffles the data due to the sampler we are using\n",
    "        return loader\n",
    "\n",
    "    def prepare_data(self):\n",
    "        # download data\n",
    "        InvertedMNIST(self.data_dir, train=True, download=True)\n",
    "        InvertedMNIST(self.data_dir, train=False, download=True)\n",
    "\n",
    "    def setup(self, stage=None):\n",
    "        # Assign train/val datasets for use in dataloaders\n",
    "        if stage == \"fit\" or stage is None:\n",
    "            mnist_full = InvertedMNIST(self.data_dir, train=True, transform=self.transform)\n",
    "            self.mnist_train, self.mnist_val = random_split(mnist_full, [55000, 5000])\n",
    "\n",
    "        # Assign test dataset for use in dataloader(s)\n",
    "        if stage == \"test\" or stage is None:\n",
    "            self.mnist_test = InvertedMNIST(self.data_dir, train=False, transform=self.transform)\n",
    "\n",
    "    def train_dataloader(self):\n",
    "        return self.create_dataloader(self.mnist_train)\n",
    "\n",
    "    def val_dataloader(self):\n",
    "        return self.create_dataloader(self.mnist_val)\n",
    "\n",
    "    def test_dataloader(self):\n",
    "        return self.create_dataloader(self.mnist_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d334e9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# try lora finetuning with different lora ranks\n",
    "def lora_experiment_inverted(rank):\n",
    "    state_dict = torch.load(\"model.pt\")\n",
    "    model = LitMNISTLoRA_Inverted(lora_rank=rank,)\n",
    "    model.load_state_dict(state_dict, strict=False)\n",
    "    \n",
    "    from lightning.pytorch.callbacks import LearningRateMonitor\n",
    "    lr_monitor = LearningRateMonitor(logging_interval='step')\n",
    "    \n",
    "    trainer = L.Trainer(\n",
    "        accelerator=\"auto\",\n",
    "        devices=1,\n",
    "        max_epochs=10,\n",
    "        callbacks=[lr_monitor, EarlyStopping(monitor=\"val_loss\", mode=\"min\", patience=10)],\n",
    "\n",
    "        enable_progress_bar=False\n",
    "    )\n",
    "    \n",
    "    trainer.fit(model)\n",
    "    return trainer.test()[0]['test_acc']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ea645f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name          | Type               | Params\n",
      "-----------------------------------------------------\n",
      "0 | l1            | Linear             | 50.2 K\n",
      "1 | l2            | Linear             | 4.2 K \n",
      "2 | l3            | Linear             | 650   \n",
      "3 | dropout       | Dropout            | 0     \n",
      "4 | relu          | ReLU               | 0     \n",
      "5 | val_accuracy  | MulticlassAccuracy | 0     \n",
      "6 | test_accuracy | MulticlassAccuracy | 0     \n",
      "  | other params  | n/a                | 1.1 K \n",
      "-----------------------------------------------------\n",
      "1.1 K     Trainable params\n",
      "55.1 K    Non-trainable params\n",
      "56.1 K    Total params\n",
      "0.224     Total estimated model params size (MB)\n",
      "`Trainer.fit` stopped: `max_epochs=10` reached.\n",
      "Restoring states from the checkpoint path at /home/mrigankp/OneDrive/Course/Sem 4/UMC 203/Term Paper/experiments/LoRA/MNIST/lightning_logs/version_36/checkpoints/epoch=9-step=540.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "Loaded model weights from the checkpoint at /home/mrigankp/OneDrive/Course/Sem 4/UMC 203/Term Paper/experiments/LoRA/MNIST/lightning_logs/version_36/checkpoints/epoch=9-step=540.ckpt\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\">        Test metric        </span>┃<span style=\"font-weight: bold\">       DataLoader 0        </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         test_acc          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.4456999897956848     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         test_loss         </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    1.6841665506362915     </span>│\n",
       "└───────────────────────────┴───────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1m       Test metric       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      DataLoader 0       \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│\u001b[36m \u001b[0m\u001b[36m        test_acc         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.4456999897956848    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m        test_loss        \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   1.6841665506362915    \u001b[0m\u001b[35m \u001b[0m│\n",
       "└───────────────────────────┴───────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name          | Type               | Params\n",
      "-----------------------------------------------------\n",
      "0 | l1            | Linear             | 50.2 K\n",
      "1 | l2            | Linear             | 4.2 K \n",
      "2 | l3            | Linear             | 650   \n",
      "3 | dropout       | Dropout            | 0     \n",
      "4 | relu          | ReLU               | 0     \n",
      "5 | val_accuracy  | MulticlassAccuracy | 0     \n",
      "6 | test_accuracy | MulticlassAccuracy | 0     \n",
      "  | other params  | n/a                | 2.1 K \n",
      "-----------------------------------------------------\n",
      "2.1 K     Trainable params\n",
      "55.1 K    Non-trainable params\n",
      "57.1 K    Total params\n",
      "0.229     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rank 1 Accuracy: 0.4456999897956848, Time: 18.9595 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=10` reached.\n",
      "Restoring states from the checkpoint path at /home/mrigankp/OneDrive/Course/Sem 4/UMC 203/Term Paper/experiments/LoRA/MNIST/lightning_logs/version_37/checkpoints/epoch=9-step=540.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "Loaded model weights from the checkpoint at /home/mrigankp/OneDrive/Course/Sem 4/UMC 203/Term Paper/experiments/LoRA/MNIST/lightning_logs/version_37/checkpoints/epoch=9-step=540.ckpt\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\">        Test metric        </span>┃<span style=\"font-weight: bold\">       DataLoader 0        </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         test_acc          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.6279000043869019     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         test_loss         </span>│<span style=\"color: #800080; text-decoration-color: #800080\">     1.308717131614685     </span>│\n",
       "└───────────────────────────┴───────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1m       Test metric       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      DataLoader 0       \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│\u001b[36m \u001b[0m\u001b[36m        test_acc         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.6279000043869019    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m        test_loss        \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    1.308717131614685    \u001b[0m\u001b[35m \u001b[0m│\n",
       "└───────────────────────────┴───────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name          | Type               | Params\n",
      "-----------------------------------------------------\n",
      "0 | l1            | Linear             | 50.2 K\n",
      "1 | l2            | Linear             | 4.2 K \n",
      "2 | l3            | Linear             | 650   \n",
      "3 | dropout       | Dropout            | 0     \n",
      "4 | relu          | ReLU               | 0     \n",
      "5 | val_accuracy  | MulticlassAccuracy | 0     \n",
      "6 | test_accuracy | MulticlassAccuracy | 0     \n",
      "  | other params  | n/a                | 4.2 K \n",
      "-----------------------------------------------------\n",
      "4.2 K     Trainable params\n",
      "55.1 K    Non-trainable params\n",
      "59.2 K    Total params\n",
      "0.237     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rank 2 Accuracy: 0.6279000043869019, Time: 17.5632 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=10` reached.\n",
      "Restoring states from the checkpoint path at /home/mrigankp/OneDrive/Course/Sem 4/UMC 203/Term Paper/experiments/LoRA/MNIST/lightning_logs/version_38/checkpoints/epoch=9-step=540.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "Loaded model weights from the checkpoint at /home/mrigankp/OneDrive/Course/Sem 4/UMC 203/Term Paper/experiments/LoRA/MNIST/lightning_logs/version_38/checkpoints/epoch=9-step=540.ckpt\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\">        Test metric        </span>┃<span style=\"font-weight: bold\">       DataLoader 0        </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         test_acc          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.7168999910354614     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         test_loss         </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.9004978537559509     </span>│\n",
       "└───────────────────────────┴───────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1m       Test metric       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      DataLoader 0       \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│\u001b[36m \u001b[0m\u001b[36m        test_acc         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.7168999910354614    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m        test_loss        \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.9004978537559509    \u001b[0m\u001b[35m \u001b[0m│\n",
       "└───────────────────────────┴───────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name          | Type               | Params\n",
      "-----------------------------------------------------\n",
      "0 | l1            | Linear             | 50.2 K\n",
      "1 | l2            | Linear             | 4.2 K \n",
      "2 | l3            | Linear             | 650   \n",
      "3 | dropout       | Dropout            | 0     \n",
      "4 | relu          | ReLU               | 0     \n",
      "5 | val_accuracy  | MulticlassAccuracy | 0     \n",
      "6 | test_accuracy | MulticlassAccuracy | 0     \n",
      "  | other params  | n/a                | 8.4 K \n",
      "-----------------------------------------------------\n",
      "8.4 K     Trainable params\n",
      "55.1 K    Non-trainable params\n",
      "63.5 K    Total params\n",
      "0.254     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rank 4 Accuracy: 0.7168999910354614, Time: 18.0514 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=10` reached.\n",
      "Restoring states from the checkpoint path at /home/mrigankp/OneDrive/Course/Sem 4/UMC 203/Term Paper/experiments/LoRA/MNIST/lightning_logs/version_39/checkpoints/epoch=9-step=540.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "Loaded model weights from the checkpoint at /home/mrigankp/OneDrive/Course/Sem 4/UMC 203/Term Paper/experiments/LoRA/MNIST/lightning_logs/version_39/checkpoints/epoch=9-step=540.ckpt\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\">        Test metric        </span>┃<span style=\"font-weight: bold\">       DataLoader 0        </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         test_acc          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.8108000159263611     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         test_loss         </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.6273475885391235     </span>│\n",
       "└───────────────────────────┴───────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1m       Test metric       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      DataLoader 0       \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│\u001b[36m \u001b[0m\u001b[36m        test_acc         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.8108000159263611    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m        test_loss        \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.6273475885391235    \u001b[0m\u001b[35m \u001b[0m│\n",
       "└───────────────────────────┴───────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name          | Type               | Params\n",
      "-----------------------------------------------------\n",
      "0 | l1            | Linear             | 50.2 K\n",
      "1 | l2            | Linear             | 4.2 K \n",
      "2 | l3            | Linear             | 650   \n",
      "3 | dropout       | Dropout            | 0     \n",
      "4 | relu          | ReLU               | 0     \n",
      "5 | val_accuracy  | MulticlassAccuracy | 0     \n",
      "6 | test_accuracy | MulticlassAccuracy | 0     \n",
      "  | other params  | n/a                | 16.8 K\n",
      "-----------------------------------------------------\n",
      "16.8 K    Trainable params\n",
      "55.1 K    Non-trainable params\n",
      "71.9 K    Total params\n",
      "0.287     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rank 8 Accuracy: 0.8108000159263611, Time: 17.4117 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=10` reached.\n",
      "Restoring states from the checkpoint path at /home/mrigankp/OneDrive/Course/Sem 4/UMC 203/Term Paper/experiments/LoRA/MNIST/lightning_logs/version_40/checkpoints/epoch=9-step=540.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "Loaded model weights from the checkpoint at /home/mrigankp/OneDrive/Course/Sem 4/UMC 203/Term Paper/experiments/LoRA/MNIST/lightning_logs/version_40/checkpoints/epoch=9-step=540.ckpt\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\">        Test metric        </span>┃<span style=\"font-weight: bold\">       DataLoader 0        </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         test_acc          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.8616999983787537     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         test_loss         </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.4581376016139984     </span>│\n",
       "└───────────────────────────┴───────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1m       Test metric       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      DataLoader 0       \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│\u001b[36m \u001b[0m\u001b[36m        test_acc         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.8616999983787537    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m        test_loss        \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.4581376016139984    \u001b[0m\u001b[35m \u001b[0m│\n",
       "└───────────────────────────┴───────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name          | Type               | Params\n",
      "-----------------------------------------------------\n",
      "0 | l1            | Linear             | 50.2 K\n",
      "1 | l2            | Linear             | 4.2 K \n",
      "2 | l3            | Linear             | 650   \n",
      "3 | dropout       | Dropout            | 0     \n",
      "4 | relu          | ReLU               | 0     \n",
      "5 | val_accuracy  | MulticlassAccuracy | 0     \n",
      "6 | test_accuracy | MulticlassAccuracy | 0     \n",
      "  | other params  | n/a                | 33.6 K\n",
      "-----------------------------------------------------\n",
      "33.6 K    Trainable params\n",
      "55.1 K    Non-trainable params\n",
      "88.7 K    Total params\n",
      "0.355     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rank 16 Accuracy: 0.8616999983787537, Time: 17.1165 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=10` reached.\n",
      "Restoring states from the checkpoint path at /home/mrigankp/OneDrive/Course/Sem 4/UMC 203/Term Paper/experiments/LoRA/MNIST/lightning_logs/version_41/checkpoints/epoch=9-step=540.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "Loaded model weights from the checkpoint at /home/mrigankp/OneDrive/Course/Sem 4/UMC 203/Term Paper/experiments/LoRA/MNIST/lightning_logs/version_41/checkpoints/epoch=9-step=540.ckpt\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\">        Test metric        </span>┃<span style=\"font-weight: bold\">       DataLoader 0        </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         test_acc          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.8906999826431274     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         test_loss         </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.36336445808410645    </span>│\n",
       "└───────────────────────────┴───────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1m       Test metric       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      DataLoader 0       \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│\u001b[36m \u001b[0m\u001b[36m        test_acc         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.8906999826431274    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m        test_loss        \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.36336445808410645   \u001b[0m\u001b[35m \u001b[0m│\n",
       "└───────────────────────────┴───────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name          | Type               | Params\n",
      "-----------------------------------------------------\n",
      "0 | l1            | Linear             | 50.2 K\n",
      "1 | l2            | Linear             | 4.2 K \n",
      "2 | l3            | Linear             | 650   \n",
      "3 | dropout       | Dropout            | 0     \n",
      "4 | relu          | ReLU               | 0     \n",
      "5 | val_accuracy  | MulticlassAccuracy | 0     \n",
      "6 | test_accuracy | MulticlassAccuracy | 0     \n",
      "  | other params  | n/a                | 67.2 K\n",
      "-----------------------------------------------------\n",
      "67.2 K    Trainable params\n",
      "55.1 K    Non-trainable params\n",
      "122 K     Total params\n",
      "0.489     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rank 32 Accuracy: 0.8906999826431274, Time: 16.9832 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=10` reached.\n",
      "Restoring states from the checkpoint path at /home/mrigankp/OneDrive/Course/Sem 4/UMC 203/Term Paper/experiments/LoRA/MNIST/lightning_logs/version_42/checkpoints/epoch=9-step=540.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "Loaded model weights from the checkpoint at /home/mrigankp/OneDrive/Course/Sem 4/UMC 203/Term Paper/experiments/LoRA/MNIST/lightning_logs/version_42/checkpoints/epoch=9-step=540.ckpt\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\">        Test metric        </span>┃<span style=\"font-weight: bold\">       DataLoader 0        </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         test_acc          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.9096999764442444     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         test_loss         </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.2992924451828003     </span>│\n",
       "└───────────────────────────┴───────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1m       Test metric       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      DataLoader 0       \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│\u001b[36m \u001b[0m\u001b[36m        test_acc         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.9096999764442444    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m        test_loss        \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.2992924451828003    \u001b[0m\u001b[35m \u001b[0m│\n",
       "└───────────────────────────┴───────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rank 64 Accuracy: 0.9096999764442444, Time: 17.4064 seconds\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "results = {}\n",
    "for rank in [1, 2, 4, 8, 16, 32, 64]:\n",
    "    start_time = time.time()\n",
    "    result = lora_experiment_inverted(rank)\n",
    "    end_time = time.time()\n",
    "    elapsed_time = end_time - start_time\n",
    "\n",
    "    results[rank] = (result, elapsed_time)  # Store both accuracy and time\n",
    "    print(f\"Rank {rank} Accuracy: {result}, Time: {elapsed_time:.4f} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "933d6d67",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{1: (0.4456999897956848, 18.95950484275818),\n",
       " 2: (0.6279000043869019, 17.563158988952637),\n",
       " 4: (0.7168999910354614, 18.05138874053955),\n",
       " 8: (0.8108000159263611, 17.411713361740112),\n",
       " 16: (0.8616999983787537, 17.116520881652832),\n",
       " 32: (0.8906999826431274, 16.983154296875),\n",
       " 64: (0.9096999764442444, 17.40639615058899)}"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f1e5e14",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.2637833333333333\n"
     ]
    }
   ],
   "source": [
    "# test the accuracy of the model on original mnist dataset\n",
    "# create the dataset\n",
    "og_mnist = QuantizedMNIST(PATH_DATASETS, train=True, download=True)\n",
    "\n",
    "# create a dataloader\n",
    "og_mnist_loader = DataLoader(og_mnist, batch_size=1024, shuffle=False)\n",
    "\n",
    "acc = 0\n",
    "for x, y in og_mnist_loader:\n",
    "    preds = model_inverted.predict(x)\n",
    "    acc += torch.sum(preds == y).item()\n",
    "    \n",
    "acc /= len(og_mnist)\n",
    "\n",
    "print(acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9a1dfb1",
   "metadata": {},
   "source": [
    "# Full Training with LoRA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d05ffe1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name          | Type                | Params\n",
      "------------------------------------------------------\n",
      "0 | l1            | MultiheadLoRALinear | 51.9 K\n",
      "1 | l2            | MultiheadLoRALinear | 4.4 K \n",
      "2 | l3            | MultiheadLoRALinear | 798   \n",
      "3 | dropout       | Dropout             | 0     \n",
      "4 | relu          | ReLU                | 0     \n",
      "5 | val_accuracy  | MulticlassAccuracy  | 0     \n",
      "6 | test_accuracy | MulticlassAccuracy  | 0     \n",
      "------------------------------------------------------\n",
      "1.1 K     Trainable params\n",
      "56.1 K    Non-trainable params\n",
      "57.1 K    Total params\n",
      "0.229     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9: 100%|██████████| 54/54 [00:03<00:00, 17.49it/s, v_num=10, val_loss=2.310, val_acc=0.083]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=10` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9: 100%|██████████| 54/54 [00:03<00:00, 17.38it/s, v_num=10, val_loss=2.310, val_acc=0.083]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name          | Type                | Params\n",
      "------------------------------------------------------\n",
      "0 | l1            | MultiheadLoRALinear | 53.6 K\n",
      "1 | l2            | MultiheadLoRALinear | 4.7 K \n",
      "2 | l3            | MultiheadLoRALinear | 946   \n",
      "3 | dropout       | Dropout             | 0     \n",
      "4 | relu          | ReLU                | 0     \n",
      "5 | val_accuracy  | MulticlassAccuracy  | 0     \n",
      "6 | test_accuracy | MulticlassAccuracy  | 0     \n",
      "------------------------------------------------------\n",
      "2.1 K     Trainable params\n",
      "57.1 K    Non-trainable params\n",
      "59.2 K    Total params\n",
      "0.237     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9: 100%|██████████| 54/54 [00:01<00:00, 37.97it/s, v_num=11, val_loss=2.320, val_acc=0.107]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=10` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9: 100%|██████████| 54/54 [00:01<00:00, 37.87it/s, v_num=11, val_loss=2.320, val_acc=0.107]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name          | Type                | Params\n",
      "------------------------------------------------------\n",
      "0 | l1            | MultiheadLoRALinear | 57.0 K\n",
      "1 | l2            | MultiheadLoRALinear | 5.2 K \n",
      "2 | l3            | MultiheadLoRALinear | 1.2 K \n",
      "3 | dropout       | Dropout             | 0     \n",
      "4 | relu          | ReLU                | 0     \n",
      "5 | val_accuracy  | MulticlassAccuracy  | 0     \n",
      "6 | test_accuracy | MulticlassAccuracy  | 0     \n",
      "------------------------------------------------------\n",
      "4.2 K     Trainable params\n",
      "59.2 K    Non-trainable params\n",
      "63.5 K    Total params\n",
      "0.254     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 9: 100%|██████████| 54/54 [00:03<00:00, 15.12it/s, v_num=12, val_loss=2.300, val_acc=0.145]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=10` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9: 100%|██████████| 54/54 [00:03<00:00, 15.09it/s, v_num=12, val_loss=2.300, val_acc=0.145]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name          | Type                | Params\n",
      "------------------------------------------------------\n",
      "0 | l1            | MultiheadLoRALinear | 63.8 K\n",
      "1 | l2            | MultiheadLoRALinear | 6.2 K \n",
      "2 | l3            | MultiheadLoRALinear | 1.8 K \n",
      "3 | dropout       | Dropout             | 0     \n",
      "4 | relu          | ReLU                | 0     \n",
      "5 | val_accuracy  | MulticlassAccuracy  | 0     \n",
      "6 | test_accuracy | MulticlassAccuracy  | 0     \n",
      "------------------------------------------------------\n",
      "8.4 K     Trainable params\n",
      "63.5 K    Non-trainable params\n",
      "71.9 K    Total params\n",
      "0.287     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                                            \r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mrigankp/.local/lib/python3.11/site-packages/lightning/pytorch/trainer/call.py:54: Detected KeyboardInterrupt, attempting graceful shutdown...\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name          | Type                | Params\n",
      "------------------------------------------------------\n",
      "0 | l1            | MultiheadLoRALinear | 77.4 K\n",
      "1 | l2            | MultiheadLoRALinear | 8.3 K \n",
      "2 | l3            | MultiheadLoRALinear | 3.0 K \n",
      "3 | dropout       | Dropout             | 0     \n",
      "4 | relu          | ReLU                | 0     \n",
      "5 | val_accuracy  | MulticlassAccuracy  | 0     \n",
      "6 | test_accuracy | MulticlassAccuracy  | 0     \n",
      "------------------------------------------------------\n",
      "16.8 K    Trainable params\n",
      "71.9 K    Non-trainable params\n",
      "88.7 K    Total params\n",
      "0.355     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9: 100%|██████████| 54/54 [00:03<00:00, 17.82it/s, v_num=14, val_loss=2.330, val_acc=0.093]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=10` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9: 100%|██████████| 54/54 [00:03<00:00, 17.78it/s, v_num=14, val_loss=2.330, val_acc=0.093]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name          | Type                | Params\n",
      "------------------------------------------------------\n",
      "0 | l1            | MultiheadLoRALinear | 104 K \n",
      "1 | l2            | MultiheadLoRALinear | 12.4 K\n",
      "2 | l3            | MultiheadLoRALinear | 5.4 K \n",
      "3 | dropout       | Dropout             | 0     \n",
      "4 | relu          | ReLU                | 0     \n",
      "5 | val_accuracy  | MulticlassAccuracy  | 0     \n",
      "6 | test_accuracy | MulticlassAccuracy  | 0     \n",
      "------------------------------------------------------\n",
      "33.6 K    Trainable params\n",
      "88.7 K    Non-trainable params\n",
      "122 K     Total params\n",
      "0.489     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9: 100%|██████████| 54/54 [00:03<00:00, 17.22it/s, v_num=15, val_loss=2.310, val_acc=0.0886]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=10` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9: 100%|██████████| 54/54 [00:03<00:00, 17.16it/s, v_num=15, val_loss=2.310, val_acc=0.0886]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name          | Type                | Params\n",
      "------------------------------------------------------\n",
      "0 | l1            | MultiheadLoRALinear | 158 K \n",
      "1 | l2            | MultiheadLoRALinear | 20.5 K\n",
      "2 | l3            | MultiheadLoRALinear | 10.1 K\n",
      "3 | dropout       | Dropout             | 0     \n",
      "4 | relu          | ReLU                | 0     \n",
      "5 | val_accuracy  | MulticlassAccuracy  | 0     \n",
      "6 | test_accuracy | MulticlassAccuracy  | 0     \n",
      "------------------------------------------------------\n",
      "67.2 K    Trainable params\n",
      "122 K     Non-trainable params\n",
      "189 K     Total params\n",
      "0.758     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9: 100%|██████████| 54/54 [00:03<00:00, 17.09it/s, v_num=16, val_loss=2.300, val_acc=0.124]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=10` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9: 100%|██████████| 54/54 [00:03<00:00, 17.02it/s, v_num=16, val_loss=2.300, val_acc=0.124]\n"
     ]
    }
   ],
   "source": [
    "import lte\n",
    "\n",
    "for r in [1, 2, 4, 8, 16, 32, 64]:\n",
    "      model = lte.prepare_model_for_lte(\n",
    "            LitMNIST().cuda(),\n",
    "            lte.LTEConfig.default(\n",
    "                  lora_r=r,\n",
    "                  lora_alpha=4096,\n",
    "                  num_heads=1,\n",
    "            ),\n",
    "      )\n",
    "      trainer = L.Trainer(\n",
    "            accelerator=\"auto\",\n",
    "            devices=1,\n",
    "            max_epochs=10,\n",
    "            logger=CSVLogger(save_dir=\"logs/\"),\n",
    "      )\n",
    "      print(f\"TRAINING WITH RANK {r}\")\n",
    "      trainer.fit(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7af4e9d7",
   "metadata": {},
   "source": [
    "## Measure rank of difference matrices "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9b32a5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# measure rank of a matrix\n",
    "def rank(A, tol=1e-5):\n",
    "    if tol is None:\n",
    "        tol = max(A.shape) * np.finfo(float).eps\n",
    "    u, s, vh = np.linalg.svd(A)\n",
    "    return len([x for x in s if x > tol])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37751b96",
   "metadata": {},
   "outputs": [],
   "source": [
    "# measure rank of difference matrices\n",
    "m1 = model.l1.weight.detach().cpu().numpy() - model_quantized.l1.weight.detach().cpu().numpy()\n",
    "print(rank(m1), m1.shape)\n",
    "m2 = model.l2.weight.detach().cpu().numpy() - model_quantized.l2.weight.detach().cpu().numpy()\n",
    "print(rank(m2), m2.shape)\n",
    "m3 = model.l3.weight.detach().cpu().numpy() - model_quantized.l3.weight.detach().cpu().numpy()\n",
    "print(rank(m3), m3.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac650e3a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "64 (64, 784)\n",
      "64 (64, 64)\n",
      "10 (10, 64)\n",
      "[[-0.04049366  0.03350284  0.0521169  ... -0.04037759  0.03091644\n",
      "   0.03773112]\n",
      " [ 0.00453418 -0.01002774  0.00361583 ... -0.03931092  0.02139266\n",
      "  -0.02722167]\n",
      " [ 0.01411334 -0.04798795  0.02811623 ... -0.01018235  0.01330226\n",
      "  -0.0604674 ]\n",
      " ...\n",
      " [ 0.00571409 -0.0295428  -0.01152774 ...  0.03153808 -0.01521152\n",
      "  -0.01376674]\n",
      " [ 0.00739058  0.02778394  0.06954384 ...  0.04650382  0.03017496\n",
      "   0.0300016 ]\n",
      " [-0.00749858 -0.02041606 -0.05367693 ...  0.06143498 -0.01491127\n",
      "   0.00466065]]\n"
     ]
    }
   ],
   "source": [
    "# measure rank of difference matrices\n",
    "m1 = model.l1.weight.detach().cpu().numpy() - model_inverted.l1.weight.detach().cpu().numpy()\n",
    "print(rank(m1), m1.shape)\n",
    "m2 = model.l2.weight.detach().cpu().numpy() - model_inverted.l2.weight.detach().cpu().numpy()\n",
    "print(rank(m2), m2.shape)\n",
    "m3 = model.l3.weight.detach().cpu().numpy() - model_inverted.l3.weight.detach().cpu().numpy()\n",
    "print(rank(m3), m3.shape)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
