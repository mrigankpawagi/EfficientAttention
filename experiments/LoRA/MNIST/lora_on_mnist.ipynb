{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a85fefe6-e3e9-44b2-9bdc-fc03d30080b6",
   "metadata": {},
   "source": [
    "# LoRA on MNIST  \n",
    "This notebook will attempt to implement Low-Rank Adaptation(LoRA) Finetuning from scratch on the MNIST dataset using pytorch lightning. I'm purposely using a simple model and data that way I can focus on LoRA implementation. \n",
    "\n",
    "Plan\n",
    "1. Build an MLP. Train this model to perform well on MNIST 0-4 (half of the data).\n",
    "3. Use standard finetuning approach to train this model to work on MNIST 5-9 (this will act as our baseline)\n",
    "4. Use LoRA finetuning to train the original model to work on MNIST 5-9\n",
    "5. Compare finetuning techniques (performance, memory etc)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37e02a5d-8dd2-4361-b7cf-9d33b025a410",
   "metadata": {},
   "source": [
    "Sources:\n",
    "1. https://arxiv.org/abs/2106.09685 - LoRA paper\n",
    "2. https://lightning.ai/pages/community/tutorial/lora-llm/ - (The first half offers useful starter pseudocode)\n",
    "3. https://colab.research.google.com/drive/1iERDk94Jp0UErsPf7vXyPKeiM4ZJUQ-a?usp=sharing#scrollTo=WuK0lPwcB7Ia - had some good ideas on metrics to compute about LoRA-ized model\n",
    "4. https://lightning.ai/docs/pytorch/stable/notebooks/lightning_examples/mnist-hello-world.html - starter code for building an MLP and training on MNIST\n",
    "5. https://discuss.pytorch.org/t/how-to-use-one-class-of-number-in-mnist/26276/21 - forum post on how to limit MNIST to only first or second half"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "423b1158-1d05-4a05-b5b2-f5a0edc9ba88",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mrigankp/.local/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "Seed set to 42\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "42"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import lightning as L\n",
    "from lightning.pytorch.loggers import CSVLogger\n",
    "from lightning.pytorch.callbacks import LearningRateFinder\n",
    "from lightning.pytorch.callbacks.early_stopping import EarlyStopping\n",
    "\n",
    "from pytorch_lightning import Callback\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.nn import functional as F\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "from torch.utils.data.sampler import SubsetRandomSampler\n",
    "\n",
    "import torchvision\n",
    "from torchvision.datasets import MNIST\n",
    "from torchvision import transforms\n",
    "\n",
    "from torchmetrics import Accuracy\n",
    "\n",
    "import pandas as pd\n",
    "import seaborn as sn\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# set precision to what lightning suggests for this gpu\n",
    "torch.set_float32_matmul_precision('high')\n",
    "# make results reproducible\n",
    "L.seed_everything(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c9fd83ca-88db-4682-85e1-904d4f5df759",
   "metadata": {},
   "outputs": [],
   "source": [
    "# reserved for constants\n",
    "PATH_DATASETS = 'mnist'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f7665fd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create another dataset called \"quantized_mnist\" where feature values are rounded to 0 or 255\n",
    "\n",
    "class QuantizedMNIST(MNIST):\n",
    "    def __init__(self, *args, **kwargs):\n",
    "        super().__init__(*args, **kwargs)\n",
    "        self.transform = transforms.Compose(\n",
    "            [\n",
    "                transforms.ToTensor(),\n",
    "                transforms.Lambda(lambda x: torch.round(x)),\n",
    "            ]\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d712261-bb19-459d-8272-b33e529bc613",
   "metadata": {},
   "source": [
    "Train an MLP on full MNIST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "27414d79-396d-460d-8700-aee7169c20bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LitMNIST(L.LightningModule):\n",
    "    def __init__(self, data_dir=PATH_DATASETS, hidden_size=64, lr=2e-4, ver='n'):\n",
    "        \"\"\"\n",
    "        'ver' is 'n' for normal mnist, 'q' for quantized mnist\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        \n",
    "        self.version = ver\n",
    "\n",
    "        # Set our init args as class attributes\n",
    "        self.data_dir = data_dir\n",
    "        self.hidden_size = hidden_size\n",
    "        self.lr = lr\n",
    "\n",
    "        # Hardcode some dataset specific attributes\n",
    "        self.class_names = [0,1,2,3,4,5,6,7,8,9]\n",
    "        self.min_class = min(self.class_names)\n",
    "        self.num_classes = len(self.class_names) \n",
    "        self.dims = (1, 28, 28) # the shape of an example (C x W x H)\n",
    "        channels, width, height = self.dims\n",
    "\n",
    "        self.transform = transforms.Compose(\n",
    "            [\n",
    "                transforms.ToTensor(),\n",
    "                transforms.Normalize((0.1307,), (0.3081,)),\n",
    "            ]\n",
    "        )\n",
    "\n",
    "        self.batch_size = 1024\n",
    "\n",
    "        # Define layers for model\n",
    "        self.l1 = nn.Linear(channels * width * height, hidden_size)\n",
    "        self.l2 = nn.Linear(hidden_size, hidden_size)\n",
    "        self.l3 = nn.Linear(hidden_size, self.num_classes)\n",
    "\n",
    "        self.dropout = nn.Dropout(0.1)\n",
    "        self.relu = nn.ReLU()\n",
    "\n",
    "        \n",
    "        # Define metrics\n",
    "        self.val_accuracy = Accuracy(task=\"multiclass\", num_classes=self.num_classes)\n",
    "        self.test_accuracy = Accuracy(task=\"multiclass\", num_classes=self.num_classes)\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        # preprocessing\n",
    "        x = torch.flatten(x,1)\n",
    "\n",
    "        # layer 1 (input size, hidden size)\n",
    "        x = self.l1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.dropout(x)\n",
    "\n",
    "        # layer 2 (hidden size, hidden size)\n",
    "        x = self.l2(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.dropout(x)\n",
    "\n",
    "        #layer 3 (hidden size, self.num_classes)\n",
    "        x = self.l3(x)\n",
    "                    \n",
    "        # notice that we return the log probabilities here as that is what nll loss expects in the training step\n",
    "        return F.log_softmax(x, dim=1)\n",
    "\n",
    "    def common_step(self, batch, batch_idx):\n",
    "        # define steps all of {train, val, test} will take in one place\n",
    "        x, y = batch\n",
    "        # rescale y to be 0 indexed if necessary (like when we start using mnist 5-9)\n",
    "        if self.min_class != 0:\n",
    "            y = y - self.min_class\n",
    "        \n",
    "        logits = self(x)\n",
    "        loss = F.nll_loss(logits, y)\n",
    "        return x,y, logits, loss\n",
    "        \n",
    "        \n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        _, _, _, loss = self.common_step(batch, batch_idx)\n",
    "        self.log(\"train_loss\", loss, batch_size=self.batch_size)\n",
    "        return loss\n",
    "\n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        \n",
    "        x, y, logits, loss = self.common_step(batch, batch_idx)\n",
    "        preds = torch.argmax(logits, dim=1)\n",
    "        self.val_accuracy.update(preds, y)\n",
    "\n",
    "        self.log(\"val_loss\", loss, prog_bar=True)\n",
    "        self.log(\"val_acc\", self.val_accuracy, prog_bar=True)\n",
    "\n",
    "    def test_step(self, batch, batch_idx):\n",
    "        x, y, logits, loss = self.common_step(batch, batch_idx)\n",
    "        preds = torch.argmax(logits, dim=1)\n",
    "        self.test_accuracy.update(preds, y)\n",
    "\n",
    "        self.log(\"test_loss\", loss, prog_bar=True)\n",
    "        self.log(\"test_acc\", self.test_accuracy, prog_bar=True)\n",
    "    \n",
    "    def configure_optimizers(self):\n",
    "        # we'll use adamw to match the paper\n",
    "        optimizer = torch.optim.AdamW(self.parameters(), lr=self.lr)\n",
    "        return optimizer\n",
    "\n",
    "    # the rest of the class is helper functions/hooks for configuring data/dataloader building\n",
    "    @staticmethod\n",
    "    def get_indices(dataset,class_names):\n",
    "        if isinstance(dataset, torch.utils.data.dataset.Subset):\n",
    "            targets = torch.tensor([dataset.dataset.targets[i] for i in dataset.indices])\n",
    "        else:\n",
    "            targets = dataset.targets\n",
    "\n",
    "            \n",
    "        indices =  []\n",
    "        for i in range(len(targets)):\n",
    "            if targets[i] in class_names:\n",
    "                indices.append(i)\n",
    "        return indices\n",
    "        \n",
    "    def create_dataloader(self,dataset):\n",
    "        idx = self.get_indices(dataset, self.class_names)\n",
    "        loader = DataLoader(dataset,batch_size=self.batch_size, sampler = SubsetRandomSampler(idx), num_workers=16) # Note - this necessarily shuffles the data due to the sampler we are using\n",
    "        return loader\n",
    "\n",
    "    def prepare_data(self):\n",
    "        # download data\n",
    "        if self.version == 'n':\n",
    "            MNIST(self.data_dir, train=True, download=True)\n",
    "            MNIST(self.data_dir, train=False, download=True)\n",
    "        if self.version == 'q':\n",
    "            print(\"Checkpoint-(0)\")\n",
    "            QuantizedMNIST(self.data_dir, train=True, download=True)\n",
    "            QuantizedMNIST(self.data_dir, train=False, download=True)\n",
    "\n",
    "    def setup(self, stage=None):\n",
    "        # Assign train/val datasets for use in dataloaders\n",
    "        if self.version == 'n':\n",
    "            if stage == \"fit\" or stage is None:\n",
    "                mnist_full = MNIST(self.data_dir, train=True, transform=self.transform)\n",
    "                self.mnist_train, self.mnist_val = random_split(mnist_full, [55000, 5000])\n",
    "        if self.version == 'q':\n",
    "            print(\"Checkpoint-(1)\")\n",
    "            if stage == \"fit\" or stage is None:\n",
    "                mnist_full = QuantizedMNIST(self.data_dir, train=True, transform=self.transform)\n",
    "                self.mnist_train, self.mnist_val = random_split(mnist_full, [55000, 5000])\n",
    "\n",
    "            \n",
    "\n",
    "        # Assign test dataset for use in dataloader(s)\n",
    "        if self.version == 'n':\n",
    "            if stage == \"test\" or stage is None:\n",
    "                self.mnist_test = MNIST(self.data_dir, train=False, transform=self.transform)\n",
    "        if self.version == 'q':\n",
    "            if stage == \"test\" or stage is None:\n",
    "                self.mnist_test = QuantizedMNIST(self.data_dir, train=False, transform=self.transform)            \n",
    "\n",
    "    def train_dataloader(self):\n",
    "        return self.create_dataloader(self.mnist_train)\n",
    "\n",
    "    def val_dataloader(self):\n",
    "        return self.create_dataloader(self.mnist_val)\n",
    "\n",
    "    def test_dataloader(self):\n",
    "        return self.create_dataloader(self.mnist_test)\n",
    "    \n",
    "    def predict(self, x):\n",
    "        logits = self(x)\n",
    "        return torch.argmax(logits, dim=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "dcea2f7d-cb12-44df-96b0-e832632e905f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  | Name          | Type               | Params\n",
      "-----------------------------------------------------\n",
      "0 | l1            | Linear             | 50.2 K\n",
      "1 | l2            | Linear             | 4.2 K \n",
      "2 | l3            | Linear             | 650   \n",
      "3 | dropout       | Dropout            | 0     \n",
      "4 | relu          | ReLU               | 0     \n",
      "5 | val_accuracy  | MulticlassAccuracy | 0     \n",
      "6 | test_accuracy | MulticlassAccuracy | 0     \n",
      "-----------------------------------------------------\n",
      "55.1 K    Trainable params\n",
      "0         Non-trainable params\n",
      "55.1 K    Total params\n",
      "0.220     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9: 100%|██████████| 54/54 [00:01<00:00, 36.18it/s, v_num=7, val_loss=0.244, val_acc=0.922]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=10` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9: 100%|██████████| 54/54 [00:01<00:00, 36.10it/s, v_num=7, val_loss=0.244, val_acc=0.922]\n"
     ]
    }
   ],
   "source": [
    "model = LitMNIST()\n",
    "trainer = L.Trainer(\n",
    "    accelerator=\"auto\",\n",
    "    devices=1,\n",
    "    max_epochs=10,\n",
    "    logger=CSVLogger(save_dir=\"logs/\"),\n",
    ")\n",
    "trainer.fit(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fa45d80a-ea43-41a5-a8f4-a60ac95717bb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>train_loss</th>\n",
       "      <th>val_acc</th>\n",
       "      <th>val_loss</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>epoch</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.438507</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.7400</td>\n",
       "      <td>1.281270</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.785784</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.8468</td>\n",
       "      <td>0.626183</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.540313</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       train_loss  val_acc  val_loss\n",
       "epoch                               \n",
       "0        1.438507      NaN       NaN\n",
       "0             NaN   0.7400  1.281270\n",
       "1        0.785784      NaN       NaN\n",
       "1             NaN   0.8468  0.626183\n",
       "2        0.540313      NaN       NaN"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mrigankp/.local/lib/python3.11/site-packages/seaborn/axisgrid.py:123: UserWarning: The figure layout has changed to tight\n",
      "  self._figure.tight_layout(*args, **kwargs)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<seaborn.axisgrid.FacetGrid at 0x79e6175ff350>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 616.125x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "metrics = pd.read_csv(f\"{trainer.logger.log_dir}/metrics.csv\")\n",
    "del metrics[\"step\"]\n",
    "metrics.set_index(\"epoch\", inplace=True)\n",
    "display(metrics.dropna(axis=1, how=\"all\").head())\n",
    "sn.relplot(data=metrics, kind=\"line\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f6dc1512-5f6d-46a3-8129-1cea54a92aa3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mrigankp/.local/lib/python3.11/site-packages/lightning/pytorch/trainer/connectors/checkpoint_connector.py:145: `.test(ckpt_path=None)` was called without a model. The best model of the previous `fit` call will be used. You can pass `.test(ckpt_path='best')` to use the best model or `.test(ckpt_path='last')` to use the last model. If you pass a value, this warning will be silenced.\n",
      "Restoring states from the checkpoint path at logs/lightning_logs/version_7/checkpoints/epoch=9-step=540.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "Loaded model weights from the checkpoint at logs/lightning_logs/version_7/checkpoints/epoch=9-step=540.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing DataLoader 0: 100%|██████████| 10/10 [00:00<00:00, 109.18it/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\">        Test metric        </span>┃<span style=\"font-weight: bold\">       DataLoader 0        </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         test_acc          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.9320999979972839     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         test_loss         </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.2267124056816101     </span>│\n",
       "└───────────────────────────┴───────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1m       Test metric       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      DataLoader 0       \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│\u001b[36m \u001b[0m\u001b[36m        test_acc         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.9320999979972839    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m        test_loss        \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.2267124056816101    \u001b[0m\u001b[35m \u001b[0m│\n",
       "└───────────────────────────┴───────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[{'test_loss': 0.2267124056816101, 'test_acc': 0.9320999979972839}]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# as expected our model performs well\n",
    "trainer.test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "46379ebe-33f9-468a-a833-4dfefc489f8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save model weights so we can finetune from them later\n",
    "trainer.save_checkpoint(\"model.ckpt\")\n",
    "torch.save(model.state_dict(), 'model.pt')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad0a1f3b-6fe5-4839-b8d3-92f177c86ecb",
   "metadata": {},
   "source": [
    "# Finetune on Quantized MNIST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "742a8381",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create the dataset\n",
    "quantized_mnist = QuantizedMNIST(PATH_DATASETS, train=True, download=True)\n",
    "\n",
    "# create a dataloader\n",
    "quantized_mnist_loader = DataLoader(quantized_mnist, batch_size=1024, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d4217ecc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8558166666666667\n"
     ]
    }
   ],
   "source": [
    "# test the accuracy of the model on entire quantized dataset\n",
    "acc = 0\n",
    "for x, y in quantized_mnist_loader:\n",
    "    preds = model.predict(x)\n",
    "    acc += torch.sum(preds == y).item()\n",
    "    \n",
    "acc /= len(quantized_mnist)\n",
    "\n",
    "print(acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "500cdb8b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name          | Type               | Params\n",
      "-----------------------------------------------------\n",
      "0 | l1            | Linear             | 50.2 K\n",
      "1 | l2            | Linear             | 4.2 K \n",
      "2 | l3            | Linear             | 650   \n",
      "3 | dropout       | Dropout            | 0     \n",
      "4 | relu          | ReLU               | 0     \n",
      "5 | val_accuracy  | MulticlassAccuracy | 0     \n",
      "6 | test_accuracy | MulticlassAccuracy | 0     \n",
      "-----------------------------------------------------\n",
      "55.1 K    Trainable params\n",
      "0         Non-trainable params\n",
      "55.1 K    Total params\n",
      "0.220     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checkpoint-(0)\n",
      "Checkpoint-(1)\n",
      "Sanity Checking: |          | 0/? [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9: 100%|██████████| 54/54 [00:03<00:00, 17.59it/s, v_num=8, val_loss=0.236, val_acc=0.936]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=10` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9: 100%|██████████| 54/54 [00:03<00:00, 17.48it/s, v_num=8, val_loss=0.236, val_acc=0.936]\n"
     ]
    }
   ],
   "source": [
    "# now finetune e2e on the new data\n",
    "model_quantized = LitMNIST.load_from_checkpoint(checkpoint_path=\"model.ckpt\")\n",
    "model_quantized.version = 'q'\n",
    "\n",
    "trainer = L.Trainer(\n",
    "    accelerator=\"auto\",\n",
    "    devices=1,\n",
    "    max_epochs=10,\n",
    "    logger=CSVLogger(save_dir=\"logs/\"),\n",
    ")\n",
    "trainer.fit(model_quantized)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b37c4c1e-8141-4416-a0a1-1f8e596abd17",
   "metadata": {},
   "source": [
    "# Finetune on quantized MNIST using LoRA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "27563e84-9d50-480c-9202-91d7b5ec518c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LitMNISTLoRA(L.LightningModule):\n",
    "    def __init__(self, data_dir=PATH_DATASETS, hidden_size=64, lr=2e-4, lora_rank = 8):\n",
    "        super().__init__()\n",
    "\n",
    "        # Set our init args as class attributes\n",
    "        self.data_dir = data_dir\n",
    "        self.hidden_size = hidden_size\n",
    "        self.lr = lr\n",
    "\n",
    "        # Hardcode some dataset specific attributes\n",
    "        self.class_names = [0,1,2,3,4,5,6,7,8,9]\n",
    "        self.min_class = min(self.class_names)\n",
    "        self.num_classes = len(self.class_names) \n",
    "        self.dims = (1, 28, 28) # the shape of an example (C x W x H)\n",
    "        channels, width, height = self.dims\n",
    "\n",
    "        self.transform = transforms.Compose(\n",
    "            [\n",
    "                transforms.ToTensor(),\n",
    "                transforms.Normalize((0.1307,), (0.3081,)),\n",
    "            ]\n",
    "        )\n",
    "\n",
    "        self.batch_size = 1024 # 64\n",
    "        \n",
    "        # Define layers for model\n",
    "        self.l1 = nn.Linear(channels * width * height, hidden_size)\n",
    "        self.l2 = nn.Linear(hidden_size, hidden_size)\n",
    "        self.l3 = nn.Linear(hidden_size, self.num_classes)\n",
    "\n",
    "        self.dropout = nn.Dropout(0.1)\n",
    "        self.relu = nn.ReLU()\n",
    "\n",
    "        # Define lora hyperparameters\n",
    "        self.lora_rank = lora_rank # The rank 'r' for the low-rank adaptation\n",
    "        self.lora_alpha = 1 # lora scaling factor\n",
    "        \n",
    "        # layer 1 lora layers\n",
    "        self.l1_lora_A = nn.Parameter(torch.empty(channels * width * height, self.lora_rank))\n",
    "        self.l1_lora_B = nn.Parameter(torch.empty(self.lora_rank, hidden_size))\n",
    "\n",
    "        # layer 2 lora layers\n",
    "        self.l2_lora_A =  nn.Parameter(torch.empty(hidden_size, self.lora_rank))\n",
    "        self.l2_lora_B = nn.Parameter(torch.empty(self.lora_rank, hidden_size))\n",
    "\n",
    "        # layer 3 lora layers\n",
    "        self.l3_lora_A = nn.Parameter(torch.empty(hidden_size, self.lora_rank))\n",
    "        self.l3_lora_B = nn.Parameter(torch.empty(self.lora_rank, self.num_classes))\n",
    "        \n",
    "        # Define initialization for lora layers (this ensures that the model behavior is identital to to the original model prior to finetuning)\n",
    "        for n,p in self.named_parameters():\n",
    "            if 'lora' in n:\n",
    "                if n[-1]=='A':\n",
    "                    nn.init.kaiming_uniform_(p, a=math.sqrt(5))\n",
    "                elif n[-1]=='B':\n",
    "                    nn.init.zeros_(p)\n",
    "\n",
    "        # freeze non lora weights\n",
    "        for n,p in self.named_parameters():\n",
    "            if 'lora' not in n:\n",
    "                p.requires_grad = False\n",
    "        \n",
    "        # Define metrics\n",
    "        self.val_accuracy = Accuracy(task=\"multiclass\", num_classes=self.num_classes)\n",
    "        self.test_accuracy = Accuracy(task=\"multiclass\", num_classes=self.num_classes)\n",
    "\n",
    "\n",
    "    def lora_linear(self, x, layer, lora_A, lora_B):\n",
    "        # does the work of combining outputs from normal layer and lora layer for x\n",
    "        # notice that h is the sum of two separate operations on x\n",
    "        h = layer(x)\n",
    "        h += x@(lora_A @ lora_B)*self.lora_alpha\n",
    "        return h\n",
    "        \n",
    "    def forward(self, x):\n",
    "        # preprocessing\n",
    "        x = torch.flatten(x,1)\n",
    "        \n",
    "        # layer 1 (input size, hidden size)\n",
    "        x = self.lora_linear(x, self.l1, self.l1_lora_A, self.l1_lora_B)\n",
    "        x = self.relu(x)\n",
    "        x = self.dropout(x)\n",
    "\n",
    "        # layer 2 (hidden size, hidden size)\n",
    "        x = self.lora_linear(x, self.l2, self.l2_lora_A, self.l2_lora_B)\n",
    "        x = self.relu(x)\n",
    "        x = self.dropout(x)\n",
    "\n",
    "        #layer 3 (hidden size, self.num_classes)\n",
    "        x = self.lora_linear(x, self.l3, self.l3_lora_A, self.l3_lora_B)\n",
    "                    \n",
    "        # notice that we return the log probabilities here as that is what nll loss expects in the training step\n",
    "        return F.log_softmax(x, dim=1)\n",
    "\n",
    "    def common_step(self, batch, batch_idx):\n",
    "        # define steps all of {train, val, test} will take in one place\n",
    "        x, y = batch\n",
    "        # rescale y to be 0 indexed if necessary (like when we start using mnist 5-9)\n",
    "        if self.min_class != 0:\n",
    "            y = y - self.min_class\n",
    "        \n",
    "        logits = self(x)\n",
    "        loss = F.nll_loss(logits, y)\n",
    "        return x,y, logits, loss\n",
    "        \n",
    "        \n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        _, _, _, loss = self.common_step(batch, batch_idx)\n",
    "        self.log(\"train_loss\", loss, batch_size=self.batch_size)\n",
    "        return loss\n",
    "\n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        x, y, logits, loss = self.common_step(batch, batch_idx)\n",
    "        preds = torch.argmax(logits, dim=1)\n",
    "        self.val_accuracy.update(preds, y)\n",
    "\n",
    "        self.log(\"val_loss\", loss, prog_bar=False)\n",
    "        self.log(\"val_acc\", self.val_accuracy, prog_bar=True)\n",
    "\n",
    "    def test_step(self, batch, batch_idx):\n",
    "        x, y, logits, loss = self.common_step(batch, batch_idx)\n",
    "        preds = torch.argmax(logits, dim=1)\n",
    "        self.test_accuracy.update(preds, y)\n",
    "\n",
    "        self.log(\"test_loss\", loss, prog_bar=True)\n",
    "        self.log(\"test_acc\", self.test_accuracy, prog_bar=True)\n",
    "    \n",
    "    def configure_optimizers(self):\n",
    "        # we'll use adamw to match the paper\n",
    "        optimizer = torch.optim.AdamW(self.parameters(), lr=self.lr)\n",
    "        scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, 'min', patience=10)\n",
    "\n",
    "        return {\n",
    "        \"optimizer\": optimizer,\n",
    "        \"lr_scheduler\": {\n",
    "            \"scheduler\": scheduler,\n",
    "            \"monitor\": \"val_loss\",\n",
    "            \"frequency\": 1\n",
    "        },\n",
    "        }\n",
    "\n",
    "      \n",
    "    # the rest of the class is helper functions/hooks for configuring data/dataloader building\n",
    "    @staticmethod\n",
    "    def get_indices(dataset,class_names):\n",
    "        if isinstance(dataset, torch.utils.data.dataset.Subset):\n",
    "            targets = torch.tensor([dataset.dataset.targets[i] for i in dataset.indices])\n",
    "        else:\n",
    "            targets = dataset.targets\n",
    "\n",
    "            \n",
    "        indices =  []\n",
    "        for i in range(len(targets)):\n",
    "            if targets[i] in class_names:\n",
    "                indices.append(i)\n",
    "        return indices\n",
    "        \n",
    "    def create_dataloader(self,dataset):\n",
    "        idx = self.get_indices(dataset, self.class_names)\n",
    "        loader = DataLoader(dataset,batch_size=self.batch_size, sampler = SubsetRandomSampler(idx), num_workers=16) # Note - this necessarily shuffles the data due to the sampler we are using\n",
    "        return loader\n",
    "\n",
    "    def prepare_data(self):\n",
    "        # download data\n",
    "        QuantizedMNIST(self.data_dir, train=True, download=True)\n",
    "        QuantizedMNIST(self.data_dir, train=False, download=True)\n",
    "\n",
    "    def setup(self, stage=None):\n",
    "        # Assign train/val datasets for use in dataloaders\n",
    "        if stage == \"fit\" or stage is None:\n",
    "            mnist_full = QuantizedMNIST(self.data_dir, train=True, transform=self.transform)\n",
    "            self.mnist_train, self.mnist_val = random_split(mnist_full, [55000, 5000])\n",
    "\n",
    "        # Assign test dataset for use in dataloader(s)\n",
    "        if stage == \"test\" or stage is None:\n",
    "            self.mnist_test = QuantizedMNIST(self.data_dir, train=False, transform=self.transform)\n",
    "\n",
    "    def train_dataloader(self):\n",
    "        return self.create_dataloader(self.mnist_train)\n",
    "\n",
    "    def val_dataloader(self):\n",
    "        return self.create_dataloader(self.mnist_val)\n",
    "\n",
    "    def test_dataloader(self):\n",
    "        return self.create_dataloader(self.mnist_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "44986317-f1ec-4b53-b68d-47b0db656ac1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# try lora finetuning with different lora ranks\n",
    "def lora_experiment(rank):\n",
    "    state_dict = torch.load(\"model.pt\")\n",
    "    model = LitMNISTLoRA(lora_rank=rank,)\n",
    "    model.load_state_dict(state_dict, strict=False)\n",
    "    \n",
    "    from lightning.pytorch.callbacks import LearningRateMonitor\n",
    "    lr_monitor = LearningRateMonitor(logging_interval='step')\n",
    "    \n",
    "    trainer = L.Trainer(\n",
    "        accelerator=\"auto\",\n",
    "        devices=1,\n",
    "        max_epochs=10,\n",
    "        callbacks=[lr_monitor, EarlyStopping(monitor=\"val_loss\", mode=\"min\", patience=10)],\n",
    "\n",
    "        enable_progress_bar=False\n",
    "    )\n",
    "    \n",
    "    trainer.fit(model)\n",
    "    return trainer.test()[0]['test_acc']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b6dcee69-a9c7-4bb9-80a9-2bb5d8747cc9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/mrigankp/.local/lib/python3.11/site-packages/lightning/pytorch/trainer/connectors/logger_connector/logger_connector.py:75: Starting from v1.9.0, `tensorboardX` has been removed as a dependency of the `lightning.pytorch` package, due to potential conflicts with other packages in the ML ecosystem. For this reason, `logger=True` will use `CSVLogger` as the default logger, unless the `tensorboard` or `tensorboardX` packages are found. Please `pip install lightning[extra]` or one of them to enable TensorBoard support by default\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name          | Type               | Params\n",
      "-----------------------------------------------------\n",
      "0 | l1            | Linear             | 50.2 K\n",
      "1 | l2            | Linear             | 4.2 K \n",
      "2 | l3            | Linear             | 650   \n",
      "3 | dropout       | Dropout            | 0     \n",
      "4 | relu          | ReLU               | 0     \n",
      "5 | val_accuracy  | MulticlassAccuracy | 0     \n",
      "6 | test_accuracy | MulticlassAccuracy | 0     \n",
      "  | other params  | n/a                | 1.1 K \n",
      "-----------------------------------------------------\n",
      "1.1 K     Trainable params\n",
      "55.1 K    Non-trainable params\n",
      "56.1 K    Total params\n",
      "0.224     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=10` reached.\n",
      "Restoring states from the checkpoint path at /home/mrigankp/OneDrive/Course/Sem 4/UMC 203/Term Paper/experiments/LoRA/lightning_logs/version_22/checkpoints/epoch=9-step=540.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "Loaded model weights from the checkpoint at /home/mrigankp/OneDrive/Course/Sem 4/UMC 203/Term Paper/experiments/LoRA/lightning_logs/version_22/checkpoints/epoch=9-step=540.ckpt\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\">        Test metric        </span>┃<span style=\"font-weight: bold\">       DataLoader 0        </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         test_acc          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.9063000082969666     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         test_loss         </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.5468206405639648     </span>│\n",
       "└───────────────────────────┴───────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1m       Test metric       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      DataLoader 0       \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│\u001b[36m \u001b[0m\u001b[36m        test_acc         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.9063000082969666    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m        test_loss        \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.5468206405639648    \u001b[0m\u001b[35m \u001b[0m│\n",
       "└───────────────────────────┴───────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rank 1 Accuracy: 0.9063000082969666, Time: 34.9063 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name          | Type               | Params\n",
      "-----------------------------------------------------\n",
      "0 | l1            | Linear             | 50.2 K\n",
      "1 | l2            | Linear             | 4.2 K \n",
      "2 | l3            | Linear             | 650   \n",
      "3 | dropout       | Dropout            | 0     \n",
      "4 | relu          | ReLU               | 0     \n",
      "5 | val_accuracy  | MulticlassAccuracy | 0     \n",
      "6 | test_accuracy | MulticlassAccuracy | 0     \n",
      "  | other params  | n/a                | 2.1 K \n",
      "-----------------------------------------------------\n",
      "2.1 K     Trainable params\n",
      "55.1 K    Non-trainable params\n",
      "57.1 K    Total params\n",
      "0.229     Total estimated model params size (MB)\n",
      "`Trainer.fit` stopped: `max_epochs=10` reached.\n",
      "Restoring states from the checkpoint path at /home/mrigankp/OneDrive/Course/Sem 4/UMC 203/Term Paper/experiments/LoRA/lightning_logs/version_23/checkpoints/epoch=9-step=540.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "Loaded model weights from the checkpoint at /home/mrigankp/OneDrive/Course/Sem 4/UMC 203/Term Paper/experiments/LoRA/lightning_logs/version_23/checkpoints/epoch=9-step=540.ckpt\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\">        Test metric        </span>┃<span style=\"font-weight: bold\">       DataLoader 0        </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         test_acc          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">     0.909500002861023     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         test_loss         </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.48807552456855774    </span>│\n",
       "└───────────────────────────┴───────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1m       Test metric       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      DataLoader 0       \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│\u001b[36m \u001b[0m\u001b[36m        test_acc         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    0.909500002861023    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m        test_loss        \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.48807552456855774   \u001b[0m\u001b[35m \u001b[0m│\n",
       "└───────────────────────────┴───────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rank 2 Accuracy: 0.909500002861023, Time: 34.6526 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name          | Type               | Params\n",
      "-----------------------------------------------------\n",
      "0 | l1            | Linear             | 50.2 K\n",
      "1 | l2            | Linear             | 4.2 K \n",
      "2 | l3            | Linear             | 650   \n",
      "3 | dropout       | Dropout            | 0     \n",
      "4 | relu          | ReLU               | 0     \n",
      "5 | val_accuracy  | MulticlassAccuracy | 0     \n",
      "6 | test_accuracy | MulticlassAccuracy | 0     \n",
      "  | other params  | n/a                | 4.2 K \n",
      "-----------------------------------------------------\n",
      "4.2 K     Trainable params\n",
      "55.1 K    Non-trainable params\n",
      "59.2 K    Total params\n",
      "0.237     Total estimated model params size (MB)\n",
      "`Trainer.fit` stopped: `max_epochs=10` reached.\n",
      "Restoring states from the checkpoint path at /home/mrigankp/OneDrive/Course/Sem 4/UMC 203/Term Paper/experiments/LoRA/lightning_logs/version_24/checkpoints/epoch=9-step=540.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "Loaded model weights from the checkpoint at /home/mrigankp/OneDrive/Course/Sem 4/UMC 203/Term Paper/experiments/LoRA/lightning_logs/version_24/checkpoints/epoch=9-step=540.ckpt\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\">        Test metric        </span>┃<span style=\"font-weight: bold\">       DataLoader 0        </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         test_acc          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.9121999740600586     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         test_loss         </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.41099658608436584    </span>│\n",
       "└───────────────────────────┴───────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1m       Test metric       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      DataLoader 0       \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│\u001b[36m \u001b[0m\u001b[36m        test_acc         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.9121999740600586    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m        test_loss        \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.41099658608436584   \u001b[0m\u001b[35m \u001b[0m│\n",
       "└───────────────────────────┴───────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rank 4 Accuracy: 0.9121999740600586, Time: 25.2445 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name          | Type               | Params\n",
      "-----------------------------------------------------\n",
      "0 | l1            | Linear             | 50.2 K\n",
      "1 | l2            | Linear             | 4.2 K \n",
      "2 | l3            | Linear             | 650   \n",
      "3 | dropout       | Dropout            | 0     \n",
      "4 | relu          | ReLU               | 0     \n",
      "5 | val_accuracy  | MulticlassAccuracy | 0     \n",
      "6 | test_accuracy | MulticlassAccuracy | 0     \n",
      "  | other params  | n/a                | 8.4 K \n",
      "-----------------------------------------------------\n",
      "8.4 K     Trainable params\n",
      "55.1 K    Non-trainable params\n",
      "63.5 K    Total params\n",
      "0.254     Total estimated model params size (MB)\n",
      "`Trainer.fit` stopped: `max_epochs=10` reached.\n",
      "Restoring states from the checkpoint path at /home/mrigankp/OneDrive/Course/Sem 4/UMC 203/Term Paper/experiments/LoRA/lightning_logs/version_25/checkpoints/epoch=9-step=540.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "Loaded model weights from the checkpoint at /home/mrigankp/OneDrive/Course/Sem 4/UMC 203/Term Paper/experiments/LoRA/lightning_logs/version_25/checkpoints/epoch=9-step=540.ckpt\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\">        Test metric        </span>┃<span style=\"font-weight: bold\">       DataLoader 0        </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         test_acc          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.9133999943733215     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         test_loss         </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.3427736759185791     </span>│\n",
       "└───────────────────────────┴───────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1m       Test metric       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      DataLoader 0       \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│\u001b[36m \u001b[0m\u001b[36m        test_acc         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.9133999943733215    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m        test_loss        \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.3427736759185791    \u001b[0m\u001b[35m \u001b[0m│\n",
       "└───────────────────────────┴───────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rank 8 Accuracy: 0.9133999943733215, Time: 33.7363 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name          | Type               | Params\n",
      "-----------------------------------------------------\n",
      "0 | l1            | Linear             | 50.2 K\n",
      "1 | l2            | Linear             | 4.2 K \n",
      "2 | l3            | Linear             | 650   \n",
      "3 | dropout       | Dropout            | 0     \n",
      "4 | relu          | ReLU               | 0     \n",
      "5 | val_accuracy  | MulticlassAccuracy | 0     \n",
      "6 | test_accuracy | MulticlassAccuracy | 0     \n",
      "  | other params  | n/a                | 16.8 K\n",
      "-----------------------------------------------------\n",
      "16.8 K    Trainable params\n",
      "55.1 K    Non-trainable params\n",
      "71.9 K    Total params\n",
      "0.287     Total estimated model params size (MB)\n",
      "`Trainer.fit` stopped: `max_epochs=10` reached.\n",
      "Restoring states from the checkpoint path at /home/mrigankp/OneDrive/Course/Sem 4/UMC 203/Term Paper/experiments/LoRA/lightning_logs/version_26/checkpoints/epoch=9-step=540.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "Loaded model weights from the checkpoint at /home/mrigankp/OneDrive/Course/Sem 4/UMC 203/Term Paper/experiments/LoRA/lightning_logs/version_26/checkpoints/epoch=9-step=540.ckpt\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\">        Test metric        </span>┃<span style=\"font-weight: bold\">       DataLoader 0        </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         test_acc          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.9199000000953674     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         test_loss         </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.2971551716327667     </span>│\n",
       "└───────────────────────────┴───────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1m       Test metric       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      DataLoader 0       \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│\u001b[36m \u001b[0m\u001b[36m        test_acc         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.9199000000953674    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m        test_loss        \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.2971551716327667    \u001b[0m\u001b[35m \u001b[0m│\n",
       "└───────────────────────────┴───────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rank 16 Accuracy: 0.9199000000953674, Time: 34.5702 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name          | Type               | Params\n",
      "-----------------------------------------------------\n",
      "0 | l1            | Linear             | 50.2 K\n",
      "1 | l2            | Linear             | 4.2 K \n",
      "2 | l3            | Linear             | 650   \n",
      "3 | dropout       | Dropout            | 0     \n",
      "4 | relu          | ReLU               | 0     \n",
      "5 | val_accuracy  | MulticlassAccuracy | 0     \n",
      "6 | test_accuracy | MulticlassAccuracy | 0     \n",
      "  | other params  | n/a                | 33.6 K\n",
      "-----------------------------------------------------\n",
      "33.6 K    Trainable params\n",
      "55.1 K    Non-trainable params\n",
      "88.7 K    Total params\n",
      "0.355     Total estimated model params size (MB)\n",
      "`Trainer.fit` stopped: `max_epochs=10` reached.\n",
      "Restoring states from the checkpoint path at /home/mrigankp/OneDrive/Course/Sem 4/UMC 203/Term Paper/experiments/LoRA/lightning_logs/version_27/checkpoints/epoch=9-step=540.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "Loaded model weights from the checkpoint at /home/mrigankp/OneDrive/Course/Sem 4/UMC 203/Term Paper/experiments/LoRA/lightning_logs/version_27/checkpoints/epoch=9-step=540.ckpt\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\">        Test metric        </span>┃<span style=\"font-weight: bold\">       DataLoader 0        </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         test_acc          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.9253000020980835     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         test_loss         </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.26633894443511963    </span>│\n",
       "└───────────────────────────┴───────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1m       Test metric       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      DataLoader 0       \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│\u001b[36m \u001b[0m\u001b[36m        test_acc         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.9253000020980835    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m        test_loss        \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.26633894443511963   \u001b[0m\u001b[35m \u001b[0m│\n",
       "└───────────────────────────┴───────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name          | Type               | Params\n",
      "-----------------------------------------------------\n",
      "0 | l1            | Linear             | 50.2 K\n",
      "1 | l2            | Linear             | 4.2 K \n",
      "2 | l3            | Linear             | 650   \n",
      "3 | dropout       | Dropout            | 0     \n",
      "4 | relu          | ReLU               | 0     \n",
      "5 | val_accuracy  | MulticlassAccuracy | 0     \n",
      "6 | test_accuracy | MulticlassAccuracy | 0     \n",
      "  | other params  | n/a                | 67.2 K\n",
      "-----------------------------------------------------\n",
      "67.2 K    Trainable params\n",
      "55.1 K    Non-trainable params\n",
      "122 K     Total params\n",
      "0.489     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rank 32 Accuracy: 0.9253000020980835, Time: 24.8980 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=10` reached.\n",
      "Restoring states from the checkpoint path at /home/mrigankp/OneDrive/Course/Sem 4/UMC 203/Term Paper/experiments/LoRA/lightning_logs/version_28/checkpoints/epoch=9-step=540.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "Loaded model weights from the checkpoint at /home/mrigankp/OneDrive/Course/Sem 4/UMC 203/Term Paper/experiments/LoRA/lightning_logs/version_28/checkpoints/epoch=9-step=540.ckpt\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\">        Test metric        </span>┃<span style=\"font-weight: bold\">       DataLoader 0        </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         test_acc          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">     0.930400013923645     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         test_loss         </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.23627407848834991    </span>│\n",
       "└───────────────────────────┴───────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1m       Test metric       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      DataLoader 0       \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│\u001b[36m \u001b[0m\u001b[36m        test_acc         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    0.930400013923645    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m        test_loss        \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.23627407848834991   \u001b[0m\u001b[35m \u001b[0m│\n",
       "└───────────────────────────┴───────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rank 64 Accuracy: 0.930400013923645, Time: 32.3039 seconds\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "results = {}\n",
    "for rank in [1, 2, 4, 8, 16, 32, 64]:\n",
    "    start_time = time.time()\n",
    "    result = lora_experiment(rank)\n",
    "    end_time = time.time()\n",
    "    elapsed_time = end_time - start_time\n",
    "\n",
    "    results[rank] = (result, elapsed_time)  # Store both accuracy and time\n",
    "    print(f\"Rank {rank} Accuracy: {result}, Time: {elapsed_time:.4f} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b4a7b68e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{1: (0.9063000082969666, 34.9062557220459),\n",
       " 2: (0.909500002861023, 34.65264916419983),\n",
       " 4: (0.9121999740600586, 25.24445414543152),\n",
       " 8: (0.9133999943733215, 33.73633813858032),\n",
       " 16: (0.9199000000953674, 34.570229053497314),\n",
       " 32: (0.9253000020980835, 24.897957801818848),\n",
       " 64: (0.930400013923645, 32.30386519432068)}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9a1dfb1",
   "metadata": {},
   "source": [
    "# Full Training with LoRA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5d05ffe1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name          | Type                | Params\n",
      "------------------------------------------------------\n",
      "0 | l1            | MultiheadLoRALinear | 51.9 K\n",
      "1 | l2            | MultiheadLoRALinear | 4.4 K \n",
      "2 | l3            | MultiheadLoRALinear | 798   \n",
      "3 | dropout       | Dropout             | 0     \n",
      "4 | relu          | ReLU                | 0     \n",
      "5 | val_accuracy  | MulticlassAccuracy  | 0     \n",
      "6 | test_accuracy | MulticlassAccuracy  | 0     \n",
      "------------------------------------------------------\n",
      "1.1 K     Trainable params\n",
      "56.1 K    Non-trainable params\n",
      "57.1 K    Total params\n",
      "0.229     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9: 100%|██████████| 54/54 [00:03<00:00, 17.49it/s, v_num=10, val_loss=2.310, val_acc=0.083]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=10` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9: 100%|██████████| 54/54 [00:03<00:00, 17.38it/s, v_num=10, val_loss=2.310, val_acc=0.083]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name          | Type                | Params\n",
      "------------------------------------------------------\n",
      "0 | l1            | MultiheadLoRALinear | 53.6 K\n",
      "1 | l2            | MultiheadLoRALinear | 4.7 K \n",
      "2 | l3            | MultiheadLoRALinear | 946   \n",
      "3 | dropout       | Dropout             | 0     \n",
      "4 | relu          | ReLU                | 0     \n",
      "5 | val_accuracy  | MulticlassAccuracy  | 0     \n",
      "6 | test_accuracy | MulticlassAccuracy  | 0     \n",
      "------------------------------------------------------\n",
      "2.1 K     Trainable params\n",
      "57.1 K    Non-trainable params\n",
      "59.2 K    Total params\n",
      "0.237     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9: 100%|██████████| 54/54 [00:01<00:00, 37.97it/s, v_num=11, val_loss=2.320, val_acc=0.107]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=10` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9: 100%|██████████| 54/54 [00:01<00:00, 37.87it/s, v_num=11, val_loss=2.320, val_acc=0.107]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name          | Type                | Params\n",
      "------------------------------------------------------\n",
      "0 | l1            | MultiheadLoRALinear | 57.0 K\n",
      "1 | l2            | MultiheadLoRALinear | 5.2 K \n",
      "2 | l3            | MultiheadLoRALinear | 1.2 K \n",
      "3 | dropout       | Dropout             | 0     \n",
      "4 | relu          | ReLU                | 0     \n",
      "5 | val_accuracy  | MulticlassAccuracy  | 0     \n",
      "6 | test_accuracy | MulticlassAccuracy  | 0     \n",
      "------------------------------------------------------\n",
      "4.2 K     Trainable params\n",
      "59.2 K    Non-trainable params\n",
      "63.5 K    Total params\n",
      "0.254     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 9: 100%|██████████| 54/54 [00:03<00:00, 15.12it/s, v_num=12, val_loss=2.300, val_acc=0.145]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=10` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9: 100%|██████████| 54/54 [00:03<00:00, 15.09it/s, v_num=12, val_loss=2.300, val_acc=0.145]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name          | Type                | Params\n",
      "------------------------------------------------------\n",
      "0 | l1            | MultiheadLoRALinear | 63.8 K\n",
      "1 | l2            | MultiheadLoRALinear | 6.2 K \n",
      "2 | l3            | MultiheadLoRALinear | 1.8 K \n",
      "3 | dropout       | Dropout             | 0     \n",
      "4 | relu          | ReLU                | 0     \n",
      "5 | val_accuracy  | MulticlassAccuracy  | 0     \n",
      "6 | test_accuracy | MulticlassAccuracy  | 0     \n",
      "------------------------------------------------------\n",
      "8.4 K     Trainable params\n",
      "63.5 K    Non-trainable params\n",
      "71.9 K    Total params\n",
      "0.287     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                                            \r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mrigankp/.local/lib/python3.11/site-packages/lightning/pytorch/trainer/call.py:54: Detected KeyboardInterrupt, attempting graceful shutdown...\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name          | Type                | Params\n",
      "------------------------------------------------------\n",
      "0 | l1            | MultiheadLoRALinear | 77.4 K\n",
      "1 | l2            | MultiheadLoRALinear | 8.3 K \n",
      "2 | l3            | MultiheadLoRALinear | 3.0 K \n",
      "3 | dropout       | Dropout             | 0     \n",
      "4 | relu          | ReLU                | 0     \n",
      "5 | val_accuracy  | MulticlassAccuracy  | 0     \n",
      "6 | test_accuracy | MulticlassAccuracy  | 0     \n",
      "------------------------------------------------------\n",
      "16.8 K    Trainable params\n",
      "71.9 K    Non-trainable params\n",
      "88.7 K    Total params\n",
      "0.355     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9: 100%|██████████| 54/54 [00:03<00:00, 17.82it/s, v_num=14, val_loss=2.330, val_acc=0.093]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=10` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9: 100%|██████████| 54/54 [00:03<00:00, 17.78it/s, v_num=14, val_loss=2.330, val_acc=0.093]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name          | Type                | Params\n",
      "------------------------------------------------------\n",
      "0 | l1            | MultiheadLoRALinear | 104 K \n",
      "1 | l2            | MultiheadLoRALinear | 12.4 K\n",
      "2 | l3            | MultiheadLoRALinear | 5.4 K \n",
      "3 | dropout       | Dropout             | 0     \n",
      "4 | relu          | ReLU                | 0     \n",
      "5 | val_accuracy  | MulticlassAccuracy  | 0     \n",
      "6 | test_accuracy | MulticlassAccuracy  | 0     \n",
      "------------------------------------------------------\n",
      "33.6 K    Trainable params\n",
      "88.7 K    Non-trainable params\n",
      "122 K     Total params\n",
      "0.489     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9: 100%|██████████| 54/54 [00:03<00:00, 17.22it/s, v_num=15, val_loss=2.310, val_acc=0.0886]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=10` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9: 100%|██████████| 54/54 [00:03<00:00, 17.16it/s, v_num=15, val_loss=2.310, val_acc=0.0886]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name          | Type                | Params\n",
      "------------------------------------------------------\n",
      "0 | l1            | MultiheadLoRALinear | 158 K \n",
      "1 | l2            | MultiheadLoRALinear | 20.5 K\n",
      "2 | l3            | MultiheadLoRALinear | 10.1 K\n",
      "3 | dropout       | Dropout             | 0     \n",
      "4 | relu          | ReLU                | 0     \n",
      "5 | val_accuracy  | MulticlassAccuracy  | 0     \n",
      "6 | test_accuracy | MulticlassAccuracy  | 0     \n",
      "------------------------------------------------------\n",
      "67.2 K    Trainable params\n",
      "122 K     Non-trainable params\n",
      "189 K     Total params\n",
      "0.758     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9: 100%|██████████| 54/54 [00:03<00:00, 17.09it/s, v_num=16, val_loss=2.300, val_acc=0.124]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=10` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9: 100%|██████████| 54/54 [00:03<00:00, 17.02it/s, v_num=16, val_loss=2.300, val_acc=0.124]\n"
     ]
    }
   ],
   "source": [
    "import lte\n",
    "\n",
    "for r in [1, 2, 4, 8, 16, 32, 64]:\n",
    "      model = lte.prepare_model_for_lte(\n",
    "            LitMNIST().cuda(),\n",
    "            lte.LTEConfig.default(\n",
    "                  lora_r=r,\n",
    "                  lora_alpha=4096,\n",
    "                  num_heads=1,\n",
    "            ),\n",
    "      )\n",
    "      trainer = L.Trainer(\n",
    "            accelerator=\"auto\",\n",
    "            devices=1,\n",
    "            max_epochs=10,\n",
    "            logger=CSVLogger(save_dir=\"logs/\"),\n",
    "      )\n",
    "      print(f\"TRAINING WITH RANK {r}\")\n",
    "      trainer.fit(model)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
